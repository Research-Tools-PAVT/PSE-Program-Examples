%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
%%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
\documentclass[acmsmall,review]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{POPL} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2022}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
%% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption
\usepackage{mathtools}
\usepackage{algpseudocode,algorithm,algorithmicx}
\usepackage{forest}
\usepackage{csquotes}
\usepackage{minted}
\usepackage{multicol}

%%% Macros %%%

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\newcommand{\DeclareAutoPairedDelimiter}[3]{%
	\expandafter\DeclarePairedDelimiter\csname Auto\string#1\endcsname{#2}{#3}%
	\begingroup\edef\x{\endgroup
		\noexpand\DeclareRobustCommand{\noexpand#1}{%
			\expandafter\noexpand\csname Auto\string#1\endcsname*}}%
	\x}
\DeclareAutoPairedDelimiter{\deno}{\llbracket}{\rrbracket}

\newcommand*\Let[2]{\State #1 $\gets$ #2}
\newcommand*\dom[1]{\mathrm{dom}\left( #1 \right)}

% For the Case statements
% Switch Statement Commands
% New definitions
\algnewcommand\algorithmicswitch{\textbf{switch}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%
% New "environments"
\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}%
\algtext*{EndSwitch}%
\algtext*{EndCase}%

\begin{document}
	
	%% Title information
	\title[PSE]{Probabilistic Symbolic Execution}         %% [Short Title] is optional;
	%% when present, will be used in
	%% header instead of Full Title.
	%\titlenote{with title note}             %% \titlenote is optional;
	%% can be repeated if necessary;
	%% contents suppressed with 'anonymous'
	%\subtitle{Subtitle}                     %% \subtitle is optional
	%\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
	%% can be repeated if necessary;
	%% contents suppressed with 'anonymous'
	
	
	%% Author information
	%% Contents and number of authors suppressed with 'anonymous'.
	%% Each author should be introduced by \author, followed by
	%% \authornote (optional), \orcid (optional), \affiliation, and
	%% \email.
	%% An author may have multiple affiliations and/or emails; repeat the
	%% appropriate command.
	%% Many elements are not rendered, but should be provided for metadata
	%% extraction tools.
	
	%% Author with single affiliation.
	\author{First1 Last1}
	\authornote{with author1 note}          %% \authornote is optional;
	%% can be repeated if necessary
	\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
	\affiliation{
		\position{Position1}
		\department{Department1}              %% \department is recommended
		\institution{Institution1}            %% \institution is required
		\streetaddress{Street1 Address1}
		\city{City1}
		\state{State1}
		\postcode{Post-Code1}
		\country{Country1}                    %% \country is recommended
	}
	\email{first1.last1@inst1.edu}          %% \email is recommended
	
	%% Author with two affiliations and emails.
	\author{First2 Last2}
	\authornote{with author2 note}          %% \authornote is optional;
	%% can be repeated if necessary
	\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
	\affiliation{
		\position{Position2a}
		\department{Department2a}             %% \department is recommended
		\institution{Institution2a}           %% \institution is required
		\streetaddress{Street2a Address2a}
		\city{City2a}
		\state{State2a}
		\postcode{Post-Code2a}
		\country{Country2a}                   %% \country is recommended
	}
	\email{first2.last2@inst2a.com}         %% \email is recommended
	\affiliation{
		\position{Position2b}
		\department{Department2b}             %% \department is recommended
		\institution{Institution2b}           %% \institution is required
		\streetaddress{Street3b Address2b}
		\city{City2b}
		\state{State2b}
		\postcode{Post-Code2b}
		\country{Country2b}                   %% \country is recommended
	}
	\email{first2.last2@inst2b.org}         %% \email is recommended
	
	
	%% Abstract
	%% Note: \begin{abstract}...\end{abstract} environment must come
	%% before \maketitle command
	\begin{abstract}
		TODO: Write Abstract
	\end{abstract}
	
	
	%% 2012 ACM Computing Classification System (CSS) concepts
	%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
	%% TODO: Get CSS Concepts
	\begin{CCSXML}
		<ccs2012>
		<concept>
		<concept_id>10011007.10011006.10011008</concept_id>
		<concept_desc>Software and its engineering~General programming languages</concept_desc>
		<concept_significance>500</concept_significance>
		</concept>
		<concept>
		<concept_id>10003456.10003457.10003521.10003525</concept_id>
		<concept_desc>Social and professional topics~History of programming languages</concept_desc>
		<concept_significance>300</concept_significance>
		</concept>
		</ccs2012>
	\end{CCSXML}
	
	\ccsdesc[500]{Software and its engineering~General programming languages}
	\ccsdesc[300]{Social and professional topics~History of programming languages}
	%% End of generated code
	
	
	%% Keywords
	%% comma separated list
	\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission
	
	
	%% \maketitle
	%% Note: \maketitle command must come after title commands, author
	%% commands, abstract environment, Computing Classification System
	%% environment and commands, and keywords command.
	\maketitle
	
	
	\section{Introduction}
	\label{sec:intro}
	
	One of the goals of symbolic execution is to identify whether a ``bad'' state (e.g. an \texttt{assert} failure) is reached, signifying a bug in the program.
	%
	In probabilistic programs, we are often more interested in either whether a ``bad'' state is reached too often, or, conversely, whether the ``good'' states are reached often enough.
	
	
	\subsection{Contributions}
	\label{sec:contrib}
	
	\section{Motivating Example}
	\label{sec:motiv_example}
	
	The Monty Hall problem~\cite{selvin1975} is a classic probability puzzle based on the American television show, \textit{Let's Make a Deal}, which showcases how subtle probabilistic reasoning can be.
	%
	The problem itself is simple:
	\begin{displayquote}
		You are a contestant on a gameshow and behind one of three doors there is a car and behind the others, goats.
		% 
		You pick a door and the host, who knows what is behind each of the doors, opens a different door, which has a goat.
		% 
		The host then offers you the choice to switch to the remaining door.
		% 
		Should you?
	\end{displayquote}
	While it may seem unintuitive, regardless of the contestant's original door choice, the contestant who always switches doors will win the car $\frac{2}{3}$ of the time, as opposed to a $\frac{1}{3}$ chance.
	
	
	\begin{figure}\centering
		\begin{multicols}{2}
			\inputminted[fontsize=\footnotesize,linenos]{c}{montyhall.c}
		\end{multicols}
		\caption{C code for the Monty Hall Problem}
		\label{fig:montyhall}
	\end{figure}
	
	
	We can represent this problem as a probabilistic program, as shown in Fig.~\ref{fig:montyhall}, where $\mathtt{choice} \in [1,3]$ and is the door which is originally chosen by the contestant and $\mathtt{door\_switch}$ is \texttt{true} if the contestant wants to switch doors when asked, and \texttt{false} otherwise.
	%
	Supposedly if $\mathtt{door\_switch} = \mathtt{true}$, regardless of the value of \texttt{choice}, \texttt{monty\_hall} should return \texttt{true} (i.e. the car is won) $\frac{2}{3}$ of the time.
	%
	The problem thus becomes, given a probabilistic program with discrete sampling statements, and a program property, how do we verify that the program satisfies the property?
	
	
	One typical solution would be to run a simulation on random inputs and compute the probability of winning if $\mathtt{door\_switch} = \mathtt{true}$, and the probability of winning if $\mathtt{door\_switch} = \mathtt{false}$.
	%
	While for this program this would work as the input space is tiny, the resulting output distributions would be absent any formal guarantees and only be an approximation.
	
	% 1) What is the problem? Given a program, and a property we wish to check, how do we prove that property?
	% - Introduce the program and the property
	% 2) Given a program, how do we generate the tree with probabilities?
	% 3) Given a tree, how do we make queries against the tree to actually verify the property?
	
	\section{Probabilistic Symbolic Execution Algorithm}
	\label{sec:pse}
	In this section, we present our technique for augmenting traditional symbolic execution to support probabilistic programs with discrete sampling instructions. 
	%
	We begin with a short review of a traditional symbolic execution algorithm and then discuss how we calculate exact path probabilities.
	
	\subsection{Background}
	\label{sec:trad_sym_exec}
	{\color{red} Subhajit \& Sumit: If you could add a high-level description of symb. exec., maybe an algorithm, that would be great!\\}
	\textit{Symbolic execution} is a program analysis technique where a program is run on \textit{symbolic} inputs and all program operations are replaced with those which manipulate these symbolic variables.
	%
	During execution, program state is encoded symbolically in two parts: a path condition which is a conjunctive formula, $\varphi$, which records the branch conditions which are true for that particular path, and a mapping from program variables to symbolic expressions containing constants and \textit{symbolic variables}, $\sigma$.
	%
	When execution reaches an assignment of the form $\mathtt{x} = e$, where $e$ is a constant or program variable, $\sigma[\mathtt{x}] = \sigma[e]$.
	%
	Similarly, if $e = e_1 \oplus e_2$, where $\oplus$ is an arbitrary binary operation, $\sigma[\mathtt{x}] = \sigma[e_1] \oplus \sigma[e_2]$. 
	%
	When execution reaches a branch guarded by the condition $c$, execution proceeds down both branches, one where $\varphi = \varphi \wedge \sigma[c]$, and the other where $\varphi = \varphi \wedge \neg \sigma[c]$. 
	
	\subsection{Adding Probabilistic Sampling}
	We now consider the problem of performing symbolic execution on a simple imperative probabilistic programming language, \textbf{pWhile}:
	%
	\[
	S := \mathbf{skip} \mid \mathtt{x} \leftarrow e \mid \mathtt{x} \xleftarrow{\$} d \mid S_1 ; S_2 \mid \mathbf{if}~e~\mathbf{then}~S_1~\mathbf{else}~S_2 \mid \mathbf{while}~e~\mathbf{do}~S 
	\]
	
	Above, $\mathtt{x}$ is a program variable, $e$ is an expression, and $d$ is a \textit{discrete} distribution expression. 
	%
	In order to support sampling instructions we make the following additions to traditional symbolic execution:
	%
	\begin{itemize}
		\item \textit{Probabilistic symbolic variables.} We distiguish two types of symbolic variables: \textit{universal} symbolic variables (identical to those in traditional symbolic execution), and \textit{probabilistic} symbolic variables.
		% 
		For each unique sampling instruction a new probabilistic symbolic variable is created to denote the result of sample.
		\item \textit{Distribution map.} We add a new mapping from probabilistic symbolic variables to distribution expressions, $P$, which tracks the distribution from which a probabilistic symbolic variable was originally sampled from.
		\item \textit{Path probability.} For each path, we adjoin a path probability expression, $p$, which is parameterized by universal symbolic variables.
	\end{itemize}
	
	\begin{algorithm}[H]
		\caption{PSE Assignment Algorithm}
		\label{alg:assign}
		\begin{algorithmic}[1]
			\Function{PSEAssignment}{$\mathtt{x}, e, \varphi, \sigma, P$}
			\Let{$e_{sym}$}{$\sigma[e]$}
			\State{$\sigma[\mathtt{x}] = e_{sym}$}
			\State\Return{$(\varphi,\sigma,P)$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{paragraph}{Assignment}
		For assignment statements of the form $\mathtt{x} \leftarrow e$, where $\mathtt{x}$ is a \textit{program} variable and $e$ is an expression, probabilistic symbolic execution proceeds identically to traditional symbolic execution, as detailed in Alg.~\ref{alg:assign}.
	\end{paragraph}
	
	\begin{algorithm}
		\caption{PSE Sampling Algorithm}
		\label{alg:sample}
		\begin{algorithmic}[1]
			\Function{PSESample}{$\mathtt{x}, d, \varphi, \sigma, P$}
			\Let{$\delta$}{Generate a fresh probabilistic symbolic variable}
			\State{$\sigma[\mathtt{x}] = \delta$}
			\State{$P[\delta] = d$}
			\State\Return{$(\varphi,\sigma,P)$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{paragraph}{Sampling}
		For sampling statements, $\mathtt{x} \xleftarrow{\$} d$, where $\mathtt{x}$ is a \textit{program} variable and $d$ is a distribution expression, Alg.~\ref{alg:sample} is used.
		% 
		A fresh probabilistic symbolic variable, $\delta$, is created, $\sigma$ is updated to be $\sigma[\mathtt{x}] = \delta$, and the original distribution $d$ is recorded in $P$ by setting $P[\delta] = d$.
	\end{paragraph}
	
	\begin{algorithm}
		\caption{PSE Branch Algorithm}
		\label{alg:branch}
		\begin{algorithmic}[1]
			\Function{PSEBranch}{$c, \varphi, \sigma, P$}
			\Let{$c_{sym}$}{$\sigma[c]$}
			\Let{$(\delta_1,\ldots,\delta_n)$}{$\dom{P}$}
			\Let{$(d_1,\ldots,d_n)$}{$(P[\delta_1],\ldots,P[\delta_n])$}
			\Let{$p_c$}{$\frac{\displaystyle\sum_{(v_1,\ldots,v_n) \in \dom{d_1} \times \cdots\times \dom{d_n}} [(c_{sym} \wedge \varphi)\{\delta_1 \mapsto v_1,\ldots,\delta_n \mapsto v_n\}]}{\displaystyle\sum_{(v_1,\ldots,v_n) \in \dom{d_1} \times \cdots\times \dom{d_n}}[\varphi\{\delta_1 \mapsto v_1,\ldots,\delta_n \mapsto v_n\}]}$}
			\State\Return{$((\varphi \wedge c_{sym}, \sigma,P,p_c), (\varphi \wedge \neg c_{sym}, \sigma,P,1-p_c))$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	% Symbolic Execution Algorithm.
	\begin{algorithm}
		\caption{Getting Path Constraints : Symbolic Execution}
		\label{alg:symbex}
		\begin{algorithmic}[1]
			\Function{SymbEx}{$P_{prog} : Program$}
			\Let{$\varphi_{paths}$}{[]}, {$Ex_{stack}$} $\leftarrow$ {[]}, $\Delta \leftarrow$ {[]}, $\phi_{paths} \leftarrow \phi$  \algorithmiccomment{Initialization}
			\Let{$I_{0}$}{\textsc{getStartInstruction}($P_{prog}$)}
			\Let{$S_{0}$}{[$I_{0}$, $\phi_{path}$, $\Delta$]} \algorithmiccomment{Empty Initial State}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{0}$})} \algorithmiccomment{Start with $S_{cur}$ in Execution Stack}
			\While{$Ex_{stack}$ != $\phi$}
			\Let{$S_{cur}$}{$Ex_{stack}$.\textsc{Pop}( )}, $I_{cur} \leftarrow S_{cur}[1]$ \algorithmiccomment{Start State, [$I_{0}$, $\phi_{path}$, $\Delta$]}
			\Switch{\textsc{instType}($I_{cur}$)} \label{line:inst_case}
			\Case{v := e} \algorithmiccomment{Assignment Instruction} \label{line:assign}
			\Let{$I_{cur}$}{\textsc{getNextInstruction}($I_{cur}$)}
			\Let{$S_{cur}$}{[$I_{cur}$, $\phi_{path}$, $\Delta$[v $\rightarrow$ \textsc{Eval($e$, $\Delta$)}]]}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{cur}$})}
			\EndCase
			\Case{\textbf{if} $(c_{sym})$ \textbf{then} $P_{1}$ \textbf{else} $P_{2}$} \algorithmiccomment{Branch Instruction} \label{line:branch}
			\If{(\textsc{isSat}($c_{sym}$) $\wedge$ \textsc{isSat}($\neg c_{sym}$))} \algorithmiccomment{Both cases SAT}
			\Let{$I_{1}$}{\textsc{getStartInstruction}($P_{1}$)} \Let{$I_{2}$} {\textsc{getStartInstruction}($P_{2}$)}	
			\Let{$S_{true}$}{[$I_{1}$, $\phi_{path} \wedge c_{sym}$, $\Delta$]} \label{line:true_state}
			\Let{$S_{false}$}{[$I_{2}$, $\phi_{path} \wedge (\neg c_{sym})$, $\Delta$]} \label{line:false_state}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{false}$})}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{true}$})} \algorithmiccomment{Start with True State}
			\ElsIf{\textsc{isSat}($c_{sym}$)} \algorithmiccomment{True case SAT}
			\Let{$I_{cur}$}{\textsc{getStartInstruction}($P_{1}$)}
			\Let {$S_{cur}$}{[$I_{cur}$, $\phi_{path} \wedge c_{sym}$, $\Delta$]}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{cur}$})}
			\ElsIf{\textsc{isSat}($\neg c_{sym}$)} \algorithmiccomment{False case SAT}
			\Let{$I_{cur}$}{\textsc{getStartInstruction}($P_{2}$)}
			\Let{$S_{cur}$}{[$I_{2}$, $\phi_{path} \wedge (\neg c_{sym})$, $\Delta$]}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{cur}$})}
			\Else \algorithmiccomment{Unconditional Branch}
			\Let{$I_{cur}$}{\textsc{getNextInstruction}($I_{cur}$)}
			\Let{$S_{cur}$}{[$I_{cur}$, $\phi_{path}$, $\Delta$]}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{cur}$})}
			\EndIf
			\EndCase
			\Case{\textbf{HALT}} \algorithmiccomment{Terminate Instruction}
			\Let{$\varphi_{paths}$}{$\varphi_{paths}$.\textsc{Append}($\phi_{path}$)}		
			\EndCase
			\EndSwitch
			\EndWhile \\
			\Return{$\varphi_{paths}$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{paragraph}{Branches}
		Note that with the inclusion of probabilistic symbolic variables we can now either branch on universal or probabilistic symbolic variables (or both).
		% 
		For guards whose symbolic version does not contain any probabilistic symbolic variables, probabilstic symbolic execution works nearly identically to traditional symbolic execution, save one detail: the probability of taking the branch. 
		% 
		If $c_{sym}$ is a symbolic expression which represents the guard to a branch, and $c_{sym}$ does not contain any probabilistic symbolic variables, then we define the probability of taking the ``true'' branch is $[c_{sym}]$, and the probability of taking the ``false'' branch is $[\neg c_{sym}]$, where $[Q] = 1$ if $Q$ is true, and 0 otherwise (known as Iverson brackets).
		
		
		For probabilistic branches, i.e. guards which branch on probabilistic symbolic variables, Alg.~\ref{alg:branch} is used instead of the traditional symbolic execution branch algorithm.
		% 
		Without loss of generality, consider a branch of the form $\mathbf{if}~c~\mathbf{then}~S_1~\mathbf{else}~S_2$ where $c$ is a probabilistic branch.
		% 
		As before, we define $c_{sym} = \sigma[c]$.
		% 
		The core of Alg.~\ref{alg:branch} is computing the probability of taking each branch.
		% 
		We interpret probabilistic branches as a conditioning operation on the distributions which are mentioned in the guard of the branch.
		% 
		Under this interpretation, we aim to compute the conditional probability $\Pr[c_{sym} \mid \varphi] = \frac{\Pr[c_{sym}\wedge \varphi]}{\Pr[\varphi]}$, where $\varphi$ is the current path condition formula.  
		
		
		We use a form of model counting in order to compute $p_c$, the probability of $c$ being true.
		% 
		Note that each probabilistic symbolic variable, $\delta$, is mapped to exactly one distribution, $d$, and therefore, $\delta \in \dom{d}$.
		% 
		So, assuming there are $n$ probabilistic symbolic variables, $\delta_1,\ldots,\delta_n$, and so $n$ distributions, $d_1,\ldots,d_n$, the set of all possible values $\delta_1,\ldots,\delta_n$ be is $\mathcal{D} = \dom{d_1} \times \cdots \times \dom{d_n}$.
		% 
		We then count the number of elements (or \textit{assignments}) from $\mathcal{D}$ which satisfy $c_{sym} \wedge \varphi$ and $\varphi$, and divide these two quantities as shown on line 5 of Alg.~\ref{alg:branch}.
		% 
		Note that $p_c$ is not necessarily a value, but rather a symbolic expression containing constants and universal symbolic variables.
		% 
		Additionally, we exploit the fact that the sum of the conditional probabilities of the branch outcomes is 1, which allows us to avoid computing the probability of taking the ``false'' branch directly.
	\end{paragraph}
	
	
	\begin{figure}[h]
		\centering
		\begin{subfigure}{.3\textwidth}
			\centering
			{\small
				\begin{algorithmic}[1]
					\State{$\mathtt{x}\xleftarrow{\$}\mathrm{UniformInt}(1,3)$}
					\State{$\mathtt{y}\xleftarrow{\$}\mathrm{UniformInt}(1,3)$}
					\If{$\mathtt{x} > 1$}
					\If{$\mathtt{x} < \mathtt{y}$}
					\State\Return{$\mathtt{True}$}
					\EndIf
					\Else
					\State\Return{$\mathtt{False}$}
					\EndIf
				\end{algorithmic}
			}
			\caption{Program}
			\label{fig:exam_program}
		\end{subfigure}
		\begin{subfigure}{.69\textwidth}
			\centering
			{\small
				\begin{forest}baseline,for tree=draw,
					[{$\varphi=\top$},align=center, base=bottom
					[{$\varphi = \delta_1 > 1$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{2}{3}$} }
					[{$\varphi = (\delta_1 > 1) \wedge (\delta_1 < \delta_2)$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{1}{6}$} }
					[{\texttt{True}}]]
					[{$\varphi = (\delta_1 > 1) \wedge \neg(\delta_1 < \delta_2)$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{5}{6}$} }
					[{\texttt{False}}]]]
					[{$\varphi = \neg(\delta_1 > 1)$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{1}{3}$} }
					[{\texttt{False}}]]]
				\end{forest}
			}
			\caption{Execution Tree}
			\label{fig:exam_tree}
			
		\end{subfigure}
		\caption{An example program and its symbolic execution tree}
		\label{fig:example}
	\end{figure}
	
	\begin{paragraph}{Example}
		Consider the code in Fig.~\ref{fig:exam_program} and suppose you wish to calculate the probability of the program returning \texttt{True}.
		%
		Following Alg.~\ref{alg:sample} for lines 1,2, we generate fresh probabilistic symbolic variables for $\mathtt{x}$ and $\mathtt{y}$, $\delta_1$ and $\delta_2$, respectively.
		%
		We also store the distributions which $\delta_1$ and $\delta_2$ are samples from, namely the discrete uniform distribution $\mathcal{U}\{1,3\}$.
		%
		In our notation, we say that $\sigma = \{ \mathtt{x} \mapsto \delta_1, \mathtt{y} \mapsto \delta_2 \}$ and $P = \{ \delta_1,\delta_2 \mapsto \mathcal{U}\{1,3\} \}$.
		%
		Now following Alg.~\ref{alg:branch} to process line 4 of Fig.~\ref{fig:exam_program}, note that $\mathcal{D} = \{1,2,3\} \times \{1,2,3\}$ and 
		
		\begin{align*}
			p_c = \Pr[\delta_1 < \delta_2 \mid \delta_1 > 1] &= \frac{\Pr[(\delta_1 < \delta_2) \wedge (\delta_1 > 1)]}{\Pr[\delta_1 > 1]}\\
			&= \frac{\displaystyle\sum_{(v_1,v_2) \in \mathcal{D}} [(\delta_1 < \delta_2) \wedge (\delta_1 > 1)\{\delta_1 \mapsto v_1, \delta_2 \mapsto v_2\}]}{\displaystyle\sum_{(v_1,v_2) \in \mathcal{D}} [(\delta_1 > 1)\{\delta_1 \mapsto v_1\}]}\\
			&= \frac{1}{6}
		\end{align*}
	\end{paragraph}
	
	\subsection{Query Generation}
	\label{sec:query_gen}
	
	At this point, we have an execution tree where each branch is annotated with the probability of taking the true and false branch.
	%
	From this tree we construct a set of paths which are represented by a path condition and set of probabilities.
	%
	If there are $n$ paths, and $\varphi_i$ is the $i^\text{th}$ path condition, and $p_{i_j}$ is the probability of the $j^{\text{th}}$ branch in the $i^{\text{th}}$ path, then we have $\{ (\varphi_1, \{p_{1_1},\ldots,p_{1_{k_1}}\}), \ldots, (\varphi_n, \{p_{n_1},\ldots,p_{n_{k_n}}\})\}$.
	%
	To calculate the probability of an entire path, or equivalently, the probability of a path condition, $\varphi$, being true, we can simply multiple each of the branch probabilities.
	%
	Recall that $p_{i_j}$ is the \textit{conditional} probability of the $j^{\text{th}}$ branch condition being true along path $i$.
	%
	Since $\varphi_i$ is the conjunction of each of the $k_i$ branch conditions, the probability of taking the entire path can be computed using the rule $\Pr[A \wedge B] = \Pr[A \mid B]\Pr[B]$ where $A$ and $B$ are any two events.
	%
	In other words, since $\varphi_i = c_{i_1} \wedge \cdots \wedge c_{i_{k_i}}$, then
	\begin{align*}
		\Pr[\varphi_i] &= \Pr[c_{i_1} \wedge \cdots \wedge c_{i_{k_i}}]\\
		&= \Pr[c_{i_1} (c_{i_2} \wedge \cdots \wedge c_{i_{{k_i}-1}} \wedge c_{i_{k_i}})]\\
		&= p_{i_1} \cdot \Pr[c_{i_2} \wedge \cdots \wedge c_{i_{k_i}}]\\
		&\vdots\\
		&= \displaystyle\prod_{j=1}^{k_i} p_{i_j}
	\end{align*}
	
	So, if we let $p_i = \prod_{j=1}^{k_i} p_{i_j}$, then we can simplify our set of paths to $\Phi = \{ (\varphi_1, p_1), \ldots, (\varphi_n, p_n)\}$.
	
	
	In our interpretation, the ultimate goal of probabilistic symbolic execution is to verify properties of probabilistic programs.
	%
	In a probabilistic setting this often equates to either proving the upper bound of reaching some ``bad'' state, or proving the lower bound of reaching some ``good'' state.
	%
	We achieve this through queries to an SMT solver, such as Z3~\cite{demoura2008}.
	%
	There are three components to our queries: 1) a universal quantification over the universal symbolic variables, 2) a filtering condition specifying what a ``good'' or ``bad'' state is, and 3) a desired upper/lower bound, potentially parameterized by universal symbolic variables.
	%
	\begin{enumerate}
		\item If a program has $m$ universal symbolic variables, $\alpha_1,\ldots,\alpha_m$, we begin the query with a universal quantification, $\forall \alpha_1,\ldots,\alpha_m$, in order to reason over any setting of the non-probabilistic program variables.
		\item A \textit{filtering condition}, $\psi$, is a predicate which determines whether a path is considered ``bad'' or ``good'', depending on the property.
		% 
		Some example conditions are whether: a certain value is returned, a false positive (or negative) occurred, or a hash collision occurred.
		% 
		Out of all the paths, $\Phi$, we keep only those which satisfy $\psi$, $\Phi'$.
		% 
		We then sum over all of the paths in $\Phi'$, giving us the probability of $\psi$ occuring in program $S$:
		\[
		\sum_{(\varphi,p) \in \Phi'} [\varphi]\cdot p.
		\]
		Note that the probability expression $p$ is multiplied by $[\varphi]$, as during some settings of $\alpha_1,\ldots,\alpha_m$, the path represented by $\varphi$ might not be reachable, and so we should exclude that probability from the sum.
		% 
		The inclusion of the Iverson brackets achieves this desired behavior.
		\item Let $\delta$ (???) be the lower/upper bound \textit{expression} which we want to prove the $S$ does not violate.
	\end{enumerate}
	A general query then takes the form of
	\[
	\forall \alpha_1,\ldots,\alpha_m . \displaystyle \delta \sim \sum_{(\varphi,p) \in \Phi'} [\varphi]\cdot p 
	\]
	where $\sim$ is a binary relation (e.g. $>,<,\leq,\geq$).
	
	
	{\color{blue} \textbf{TODO: Finish up once the overview section is done}\\\\
		For example, in the Monty Hall problem as described in Section~\ref{sec:motiv_example}, we were only concerned with those paths that resulted in the contestant winning the car.
		%
		So, we would filter on $\psi := win = true$, restricting the set of paths to be (TODO: Add on more after writing section 2).
		%
		The probability of this occuring is then ... as ...
	}
	
	
	\subsection{Formalization}
	\label{sec:formalization}
	
	In this section we present the formalization of our method. First, we will present our notation and definitions, and then provide proofs of correctness and soundness of our technique.
	
	\subsubsection{Notation \& Definitions}
	\label{sec:notation}
	
	The goal of this section is to describe how $R=(\varphi,\sigma,P)$, the inputs to Alg.~\ref{alg:branch} is an abstraction of a \textit{distribution of program memories} before a branch guarded by a program expression $c$.
	% 
	To begin, we will define some notation:
	\begin{itemize}
		\item Let $Vars$ be the set of all program variables, $ForallSymVars$ be the set of all universal symbolic variables, $ProbSymVars$ be the set of all probabilistic symbolic variables, $SymVars = ForallSymVars \cup ProbSymVars$ be the combined set of all symbolic variables, and $Vals$ be the set of all values. 
		\item Let $a_f: ForallSymVars \rightarrow Vals$ be an assignment of universal symbolic variables to values and let $ForallAssign$ be the set of all such assignments.
		\item Similarly, let $a_p : ProbSymVars \rightarrow Vals$ be an assignment of probabilistic symbolic variables to values and let $ProbAssign$ be the set of all such assignments.
		\item Let $m : Vars \rightarrow Vals$ be a program memory which translates program variables into values, and let $Mems$ be the set of all program memories.
		\item Let $de : Mems \rightarrow (Vals \rightarrow [0,1])$ be a distribution expression parameterized by program memories, and let $DistExprs$ be the set of all distribution expressions.
		\item Let $d : ForallAssign \times Mems \rightarrow [0,1]$ be a distribution of program memories parameterized by assignments to universal symbolic variables and let $MemDists$ be the set of all parameterized distributions of program memories.
	\end{itemize}
	
	Additionally, we will use emphatic brackets for two purposes:
	\begin{itemize}
		\item If $e \in ProgExprs$ is a \textit{program} expression containing the program variables $\mathtt{x}_1,\ldots,\mathtt{x}_n \in Vars$, and $m \in Mems$, then
		\[
		\deno{e}m = \text{eval}(e[\mathtt{x}_1 \mapsto m(\mathtt{x}_1),\ldots,\mathtt{x}_n \mapsto m(\mathtt{x}_n)])
		\]
		\item If $e \in SymExprs$ is a \textit{symbolic} expression containing the symbolic variables $\alpha_1,\ldots,\alpha_n \in ForallSymVars$ and $\delta_1,\ldots,\delta_m \in ProbSymVars$, and $a_f \in ForallAssign$ and $a_p \in ProbAssign$, then
		\[
		\deno{e}a_fa_p = \text{eval}(e[\alpha_1\mapsto a_f(\alpha_1),\ldots,\alpha_n \mapsto a_f(\alpha_n), \delta_1 \mapsto a_p(\delta_1), \ldots, \delta_m \mapsto a_p(\delta_m)])
		\]
	\end{itemize}
	
	With this notation in hand, we can now define what it means for $R$ to be an abstraction of a distribution of programs memories.
	
	\begin{definition}
		\label{def:combined}
		Let $R = (\varphi, \sigma, P)$ be the abstraction generated by the symbolic execution algorithm where $\varphi: ForallAssign \times ProbAssign \rightarrow \{0,1\}$ denotes whether the path condition is true or false under the given assignments, $\sigma : Vars \rightarrow SymExprs$ is the mapping from program variables to symbolic expressions generated through symbolic execution, and $P : ForallAssign \rightarrow ProbSymVars \rightharpoonup (Vals \rightarrow [0,1])$  is the mapping from probabilistic symbolic variables to the distribution it is sampled from parameterized by assignments of forall symbolic variables.
		% 
		Additionally, for every assignment of forall symbolic variables, $a_f \in ForallAssign$, $\mathrm{domain}(P(a_f)) = \{\delta_1,\ldots,\delta_k\}$.
		% 
		Let $\alpha_1,\ldots,\alpha_l \in ForallSymVars$ be the forall symbolic variables which correspond to the $l$ parameters to the program.
		% 
		For every assignment of probabilistic and forall symbolic variables, $a_f \in ForallAssign, a_p \in ProbAssign$, let $\nu : ForallAssign \rightarrow (ProbAssign \rightarrow [0,1])$ be a distribution of assignments of probabilistic symbolic variables parameterized by assignments of forall symbolic variables, defined as
		\[
		\nu(a_f,a_p) \triangleq \prod_{i=1}^k \Pr_{v \sim P(a_f,\delta_i)}[v = a_p(\delta_i)].
		\]
		% 
		We say that a distribution $d$ satisfies our abstraction $R$ if, for all assignments of forall symbolic variables, $a_f \in ForallAssign$, $\displaystyle\Pr_{a_p' \sim \nu(a_f)}[\varphi(a_f,a_p') = 1] > 0$, and if $\mu : ForallAssign \rightarrow (ProbAssign \rightarrow [0,1])$ is defined as 
		\[
		\mu(a_f,a_p) = \cfrac{\Pr_{a_p' \sim \nu(a_f)}[a_p' = a_p \land \varphi(a_f,a_p') = 1]}{\Pr_{a_p' \sim \nu(a_f)}[\varphi(a_f,a_p')=1]}.
		\]
		Additionally, define $\text{convertToMem} : (Vars \rightarrow SymExprs) \rightarrow ForallAssign \rightarrow ProbAssign \rightarrow Mem$ as
		\begin{equation*}
			\text{convertToMem}(\sigma,a_f,a_p) \triangleq \lambda (\mathtt{x}: Vars)~.~\deno{\sigma(\mathtt{x})}a_fa_p,
		\end{equation*}
		and let $\text{convertFromMem}(\sigma,a_f,m) = (\text{convertToMem}(\sigma,a_f))^{-1}(m)$.
		% 
		Then,
		\[
		d(a_f,m) = \sum_{a_p \in \text{convertFromMem}(\sigma,a_f,m)} \mu(a_f,a_p).
		\]
	\end{definition}
	
	We additionally define the semantics for the three main types of statements which concerns probabilistic symbolic execution: assignments, probabilistic samples, and branches.
	
	\begin{definition}[Assignment Semantics]
		Let $d \in MemDists$ be a distribution of program memories parameterized by assignments to forall symbolic variables. Let $\mathtt{x} = e$ be an arbitrary assignment of the program variable $\mathtt{x} \in Vars$ to the program expression $e \in ProgExprs$. Let $\text{assign}_{\mathtt{x}=e} : Mems \rightarrow Mems$ is defined as
		\[
		\text{assign}_{\mathtt{x}=e}(m) = \lambda(\mathtt{y} : Vars)
		\begin{cases}
			\deno{e}m & \text{if $\mathtt{x} = \mathtt{y}$}\\
			m(\mathtt{y}) & \text{otherwise}
		\end{cases}
		\]
		and let $\text{unassign}_{\mathtt{x}=e} = \text{assign}_{\mathtt{x}=e}^{-1}$. Then we define $d_{\mathtt{x}=e}$ to be the distribution over program memories parameterized by assignments to forall symbolic variables after executing the assignment statement $\mathtt{x}=e$ to be
		\[
		d_{\mathtt{x}=e}(a_f,m) = \sum_{m' \in \text{unassign}_{\mathtt{x}=e}(m)} d(a_f,m').
		\]
	\end{definition}
	
	\begin{definition}[Sampling Semantics]
		Let $d \in MemDists$ be a distribution of program memories parameterized by assignments to forall symbolic variables. Let $\mathtt{x} \sim de$ be an arbitrary sampling instruction which assigns the program variable $\mathtt{x} \in Vars$ to a random element from the distribution of values parameterized by a memory, represented as a distribution expression $de \in DistExprs$. Let $\text{desample} : Vars \times Mems \rightarrow \mathcal{P}(Mems)$ be defined as
		\[
		\text{desample}(\mathtt{x},m) = \{ m'\in Mems \mid \forall (\mathtt{y} \in Vars)~.~(\mathtt{y} \neq \mathtt{x} \wedge m'(\mathtt{y}) = m(\mathtt{y}))\}.
		\]
		Then, we define $d_{\mathtt{x} \sim de}$ to be the distribution over program memories parameterized by assignments to forall symbolic variables after executing the sampling statement $\mathtt{x} \sim de$ to be
		\[
		d_{\mathtt{x} \sim de}(a_f,m) = \sum_{m' \in \text{desample}(m)} (\deno{de}a_f)(m(\mathtt{x})) \cdot d(a_f,m').
		\]
	\end{definition}
	
	\begin{definition}[Conditional Distribution of Program Memories]
		\label{def:cond}
		Let $a_f \in ForallAssign$ be an arbitrary assignment of forall symbolic variables, $c$ be a guard of an \texttt{if} condition, $d \in MemDists$ be a distribution of program memories parameterized by assignments to forall symbolic variables, and $\mathtt{x}_1,\ldots,\mathtt{x}_n \in Vars$ be all of the program variables in $c$. Then for all program memories $m \in Mems$, $d$ conditioned on a guard $c$ being true, represented as $d_c$ is defined as
		\[
		d_c(a_f,m) = \frac{\Pr_{m' \sim d(a_f)}\left[ m' = m \land \deno{c}m' = \mathtt{true} \right]}{\Pr_{m' \sim d(a_f)}\left[ \deno{c}m' = \mathtt{true} \right]}
		\]
		Similarly, for all program memories $m \in Mems$, $d$ conditioned on a guard $c$ being false, represented as $d_{\neg c}$ is defined as
		\[
		d_{\neg c}(a_f,m) = \frac{\Pr_{m' \sim d(a_f)}\left[ m' = m \land \deno{c}m' = \mathtt{false} \right]}{\Pr_{m' \sim d(a_f)}\left[ \deno{c}m' = \mathtt{false} \right]}
		\]
	\end{definition}
	
	\subsubsection{Proofs}
	\label{sec:proofs}
	
	\section{Implementation}
	\label{sec:implementation}
	
	{\color{red} Subhajit \& Sumit: Write something about KLEE and the implementation here!}
	
	We use a robust dynamic symbolic execution engine, \textsc{KLEE} to generate the \textit{path constraints} corresponding to each path that our tool explores. For each path in the program, \textsc{KLEE} stores a list of \textit{constraints} that encodes the whole path. These constraints are over \textit{program} variables that have been marked \texttt{make\_symbolic()} by the user and are stored in \textsc{KLEE} as \textit{metadata} in the \textit{state} data structure during the \textit{dynamic} symbolic execution of the program. Apart from \textit{path constraints}, the \textit{state} also contains a mapping of \textit{symbolic} variables to expressions that are either  \textit{symbolic} or \textit{concrete} (in the case of concrete execution of the program) and a list of \textit{instructions} currently getting executed as a part of the \textit{state}.	
	
	During \textit{dynamic} execution, \textsc{KLEE} executes each \textit{instruction} in the program and updates the \textit{state} along with the \textit{symbolic} variables mapping ($\Delta$) depending upon \textit{type} of the \textit{instruction} it executes as described in Algorithm~\ref{alg:symbex}. 
	\textsc{KLEE} assigns values to \textit{symbolic} variables by employing an \textsc{SMT Solver} (\textsc{Z3} as in our case) for solving the current set of \textit{constraints} seen so far in the program path and also by concretizing some of the values that get evaluated as a result of \textit{concrete} execution (Eg. return value from external function calls). 
	
	For the purpose of our implementation, we modify \textsc{KLEE} to support creation of \textit{probabilistic symbolic} variables whose values can be sampled from a distribution and dump the whole set of \textit{path} constraints that is stored in the \textit{state} corresponding to the current execution of the program at each of (1) \textbf{\textit{assignment}} [Algorithm~\ref{alg:symbex}, Line~\ref{line:assign}], (2) \textbf{\textit{branch}} [Algorithm~\ref{alg:symbex}, Line~\ref{line:branch}], \& (3) \textbf{\textit{assume}} [Algorithm~\ref{alg:symbex}, Line~\ref{line:assume}] statements. These dumps are later refined and used by the tool for further processing.
	
	{\color{blue} Upon reaching the \textit{branch} instruction at Line~\ref{line:branch} in Algorithm~\ref{alg:symbex}, based on whether the \textit{path constraints} are solvable upon adding the \textit{branch} [Line~\ref{line:branch}] condition, \textsc{KLEE} forks the current \textit{state} by making two identical copies of it and then appending to each of \textit{new} states one additional constraint encoding the \textit{true} [Line~\ref{line:true_state}] and \textit{false} [Line~\ref{line:false_state}] side of the branch and adds it to the \textit{execution} stack containing \textit{states} that need to be explored next. The process continues untill all the \textit{states} in the \textit{execution} stack are explored.}
	
	
	\section{Case Studies}
	\label{sec:case_studies}
	In this section we will briefly explain each of the case studies that we use in our evaluation (Section~\ref{sec:eval}).
	% 
	For each case study, we will explain, (1) what the algorithm does, (2) which variables are concretized, universally quantified, and probabilistic, and (3) the property we aim to verify using our technique.
	%
	Note that we frame the queries as an existential query and hope to get ``UNSAT'' in order to reason over all the possible values for the universal symbolic variables.
	
	\subsection{Freivalds' Algorithm}
	\label{sec:freivalds}
	
	Freivalds' algorithm~\cite{freivalds1977} is a randomized algorithm used to verify matrix multiplication in $\mathcal{O}(n^2)$ time.
	%
	Given three $n \times n$ matrices $A,B$, and $C$, Freivalds' algorithm checks whether $A \times B = C$ by generating a random $n \times 1$ vector containing 0s and 1s, $\vec{r}$ and checks whether $A \times (B\vec{r}) - C\vec{r} = (0,\ldots,0)^T$.
	%
	If so, the algorithm outputs ``Yes'', and ``No'' otherwise.
	%
	However, if $A \times B \neq C$, the probability that the algorithm returns ``Yes'' is at most $\frac{1}{2}$.
	
	
	While the size of the matrices has to be concretized, the elements of the three matrices can be represented by universal symbolic variables and the elements of $r$ as probabilistic symbolic variables.
	%
	We want to verify the false positive error rate of $\frac{1}{2}$.
	%
	To do this, we can ask Z3, for a fixed $n$, whether there exist any $n \times n$ matrices $A,B$, and $C$ where $A \times B \neq C$ such that
	\[
	\Pr[\mathtt{freivalds}(A,B,C) = \text{Yes}] > \frac{1}{2}.
	\]
	
	\subsection{Randomized Response}
	\label{sec:randomized_response}
	
	Randomized response is a surveying technique which allows respondents to answer in a way that provides ``plausible deniability''
	%
	Before answering the query, a coin is flipped.
	%
	If ``tails'', then the respondent answers truthfully, if ``heads'', a second coin is flipped and the respondent answers ``Yes'' if ``heads'' and ``No'' if tails.
	%
	In fact, this method is $(\ln 3, 0)$-differentially private.
	
	
	The answer the respondent would give if they answered truthfully can be represented with a universal symbolic variable, and the results of the two coin flips as probabilistic symbolic variables.
	%
	With this model, we can prove $(\ln 3, 0)$ differential privacy by asking our method if there exists a setting of the ``truth'' such that
	\[
	\frac{\Pr[\text{Response} = \text{Yes} \mid \mathtt{text} = \text{Yes}]}{\Pr[\text{Response} = \text{Yes} \mid \mathtt{text} = \text{No}]} \neq 3
	\]
	and
	\[
	\frac{\Pr[\text{Response} = \text{No} \mid \mathtt{text} = \text{No}]}{\Pr[\text{Response} = \text{No} \mid \mathtt{text} = \text{Yes}]} \neq 3.
	\]
	
	\subsection{Reservoir Sampling}
	\label{sec:reservoir_sampling}
	
	\begin{algorithm}
		\caption{Reservoir Sampling}
		\label{alg:reservoir_sampling}
		\begin{algorithmic}[1]
			\Function{ReservoirSampling}{$A[1..n], S[1..k]$}
			\For{$i=1 \text{ to } k$}
			\Let{$S[i]$}{$A[i]$}
			\EndFor
			\For{$i=k+1\text{ to }n$}
			\Let{$j$}{$\mathrm{UniformInt}(1,i)$}
			\If{$j <= k$}
			\Let{$S[j]$}{$A[i]$}
			\EndIf
			\EndFor
			\State\Return{$S$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	Reservoir sampling is an online, randomized algorithm to get a simple random sample of $k$ elements from a population of $n$ elements.
	%
	It uses uniform integer samples to maintain a set of $k$ elements drawn from the set of $n$ elements.
	%
	For the full algorithm, see Alg.~\ref{alg:reservoir_sampling}.
	
	
	The sizes of both the population, $n$, and the sample, $k$, need to be concretized.
	%
	The elements from $A$, are universal symbolic variables, and each sample, $j$, are probabilistic symbolic variables.
	%
	The property that we want to check is whether each sample has an equal probability of being returned by Alg.~\ref{alg:reservoir_sampling}, namely $\frac{1}{\binom{n}{k}}$.
	
	\subsection{Schwartz-Zippel Lemma}
	\label{sec:schwartz-zippel}
	
	The Schwartz-Zippel lemma is a probabilistic method of polynomial identity testing, that is, the problem of determining whether a given multivariate polynomial is identially equal to 0 or not.
	%
	Given a non-zero polynomial of total degree $d$, $P$, over a field $F$, and $r_1,\ldots,r_n$ selected at random from a subset of $F$, say $S$, then the lemma states that
	\[
	\Pr[P(r_1,\ldots,r_n) = 0] \leq \frac{d}{\abs{S}}.
	\]
	
	
	The number of terms in $P$, $n$, has to be concretized, the degrees of each of the terms, and the size of the subset $S$ all need to be concretized.
	%
	The coefficients are represented as universal symbolic variables and $r_1,\ldots,r_n$ are probabilistic symbolic variables.
	%
	The property that we want to check is whether there exists a non-zero polynomial, $P$, such that
	\[
	\Pr[P(r_1,\ldots,r_n) = 0] > \frac{d}{\abs{S}}.
	\]
	
	\subsection{Bloom Filter}
	\label{sec:bloom_filter}
	
	A Bloom filter is a space-efficient, probabilistic data structure used to rapidly determine whether an element is in a set.
	%
	A Bloom filter is a bit-array of $n$ bits and $k$ associated hash functions, each of which maps elements in the set to places in the bit-array.
	%
	To insert an element, $x$, into the filter, $x$ is hashed using each of the $k$ hash functions to get $k$ array positions.
	%
	All of the bits at these positions are set to 1.
	%
	To check whether an element $y$ is in the filter, $y$ is again hashed by each of the hash functions to get $k$ array positions.
	%
	The bits at each of these positions are checked and the filter reports that $y$ is in the filter if, and only if, each of the bits are set to 1.
	%
	Note that false positives are possible due to hash collisions, but false negatives are not.
	
	
	In order to bound the false positive error rate, most implementations of Bloom filters take in the expected number of elements to be inserted as well as the desired false positive error rate.
	%
	From these two quantities, the optimal size of the bit-array, $n$, as well as the number of hash functions, $k$ can be computed.
	%
	If $m$ is the expected number of elements and $\varepsilon$ is the desired error rate, then
	\begin{align*}
		n &= - \frac{m\ln \varepsilon}{(\ln 2)^2}\\
		k &= - \frac{\ln \varepsilon}{\ln 2}
	\end{align*}
	%
	We want to prove that for a given $m$ and $\varepsilon$ that the actual false positive rate does not exceed $\varepsilon$.
	
	
	With our method, $m$ and $\varepsilon$ first need to be concretized. 
	%
	Then, we insert $m$ elements $x_i$, where each $x_i$ can be represented using a universal symbolic variable.
	%
	We model each of the $k$ uniform hash functions using the method described in Sec. (TODO: Insert bit about hash functions).
	%
	We then want to check if there exist $x_1,\ldots,x_m$ such that the false positive rate exceeds $\varepsilon$.
	
	\subsection{Quicksort}
	\label{sec:quicksort}
	
	Quicksort is a popular sorting algorithm which uses partitioning in order to achieve efficient sorting.
	%
	One way to choose a pivot element is by way of a uniform random sample.
	%
	Using this pivot method, the expected number of pivots required is $1.386 n \log_2(n)$ where $n$ is the length of the array.
	%
	If we concretize the length of the array, but represent the elements as universal symbolic variables, we can compute the expected number of pivots required to sort the array.
	
	
	\section{Evaluation}
	\label{sec:eval}
	
	\section{Related Work}
	\label{sec:related}
	{\color{red} Subhajit \& Sumit: If you could both start looking into related work (Mayhap, original PSE paper, Axprof, P4WN, PSI), that would be great!}
	\section{Conclusion \& Future Work}
	\label{sec:conclusion}
	
	
	%% Acknowledgments
	\begin{acks}                            %% acks environment is optional
		%% contents suppressed with 'anonymous'
		%% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
		%% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
		%% acknowledge financial support and will be used by metadata
		%% extraction tools.
		% This material is based upon work supported by the
		% \grantsponsor{GS100000001}{National Science
		%   Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
		% No.~\grantnum{GS100000001}{nnnnnnn} and Grant
		% No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
		% conclusions or recommendations expressed in this material are those
		% of the author and do not necessarily reflect the views of the
		% National Science Foundation.
	\end{acks}
	
	
	%% Bibliography
	\bibliography{main}
	
	
	%% Appendix
	\appendix
	\section{Appendix}
	
	Text of appendix \ldots
	
\end{document}