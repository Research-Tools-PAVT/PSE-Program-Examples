\documentclass[usenames,dvipsnames,acmsmall]{acmart}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[nounderscore]{syntax}
\usepackage{bussproofs}
\usepackage{mathtools}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{minted}
\usepackage{colortbl}
\usepackage{multirow}
\usepackage{minted}

\begin{document}
	\begin{figure}
		\begin{minted}{python}
	
	double prob, path_prob = 1, choice_prob = 1;
	int sum = 0;
	
	klee_make_symbolic(&prob, f"prob_sym_{i}");
	for i in range(10):
		int d;
		klee_make_symbolic(&d, f"d_sym_{i}");
	
		d = bernoulli(prob);
		(d == 1) ? choice_prob = prob : choice_prob = (1 - prob);
		path_prob = path_prob * choice_prob;
		
		sum = sum + d;
		
	klee_dump(path_prob)
	klee_dump(sum) // E[heads in "n" runs] 
		\end{minted}
		\caption{Program listing for $n$ bernoulli trails experiment.}
	\end{figure}

We consider a independent $bernoulli$ trials here of flipping a fair coin "$n$" times. 
\[ 
{choice\_prob} = 
\begin{cases} 
	p & \textrm{if $d$ value is 1 corresponding to getting a "heads"} \\
	1-p & \textrm{if $d$ value is 0 corresponding to getting a "tails"}
\end{cases}
\]

concretely, on the $i^{th}$ run \texttt{$\vec{d}$} can have a value as below, \texttt{one-hot} encoded $w.r.t$ the outcome of $heads$ or $tails$.
\[
\vec{d}_{i} = encode(<0,0,0,1,1,0,1,1,1,0>)
\]

Based on the value of the $\vec{d}_{i}$, we get $w_{i}$ value using $choice\_prob$. 
\begin{equation}
	w_{i} = {(p)^{x_i} * (1-p)^{n-x_i}}
\end{equation}
where $x_i$ denotes the number of $heads$ in the $i^{th}$ randomized run and for $n$ runs. \texttt{n = 10} for the case in the above example. \\
\begin{equation}
	w_{i} = {(p)^{x_i} * (1-p)^{10-x_i}}
\end{equation}
We consider top "$k$" randomized runs now for the optimization query. The expression for \texttt{optimization} thus becomes 
\[	
	maximize(\sum_{i=1}^{k}{w_i})
\]
On substituting the value of $w_i$ from (1).
\begin{equation}	
	maximize(\sum_{i=1}^{k}{(p)^{x_i} * (1-p)^{n-x_i}})
\end{equation}

\begin{figure}
	\begin{equation}	
		Objective = maximize(\sum_{i=1}^{k}{(p)^{x_i} * (1-p)^{n-x_i}}) \quad \mid \forall (i, j) [{x_i} \neq {x_j}]
	\end{equation}
	\caption{Optimization Expression for $k$ randomized paths}
	\label{eq:optimization-1}
\end{figure}

After performing the optimization above, we get different values of $\vec{d_i}$. For $i^{th}$ randomized run. we get a \texttt{single} one hot encoded \texttt{$\vec{d}$} vector. We show below the encoding for a few $i$ values. 
\[
\vec{d}_{1} = encode(<0,0,0,1,1,0,1,1,1,0>)
\]
\[
\vec{d}_{3} = encode(<0,1,0,1,1,0,0,0,1,0>)
\]
\[
\vec{d}_{4} = encode(<1,0,1,0,1,0,1,1,0,1>)
\]
\[
...
\]

We run the optimization by renaming the $k$ \texttt{pse} variables set appropriately and then impose the $distinct$ clause so that we don't run the optimization on the same $randomized$ runs again. \\

For best approximation of the expected value of heads in $n$ trials,
\begin{equation}	
	w_i = \prod_{j=1}^n choice\_prob_{i}(j) ,
	\quad
	sum_i = \sum_{j=1}^n components(\vec{d_i}) ,
\end{equation}
\begin{equation}
	EV(heads) = (\sum_{i=1}^{k}{w_i * sum_i}),
	\quad
	Error = n * prob - EV(heads)
\end{equation}
where both $w_i$ and $sum_i$ can both be computed from the corresponding $\vec{d_i}$ expression we get from the $model$  of the $optimization$ query Eq~\ref{eq:optimization-1}

\section{Expression for $k$-paths}

For $k = 5$ \& $n = 10$ the two \texttt{constraint} sets and \texttt{optimization} expressions are as follows : 

\begin{equation}	
	w_1 = \prod_{j=1}^{10} choice\_prob_{1}(j) ,
	\quad
	sum_1 = \sum_{j=1}^{10} components(\vec{d_1}) ,
\end{equation}
\begin{equation}	
	w_2 = \prod_{j=1}^{10} choice\_prob_{2}(j) ,
	\quad
	sum_2 = \sum_{j=1}^{10} components(\vec{d_2}) ,
\end{equation}
\begin{equation}	
	w_3 = \prod_{j=1}^{10} choice\_prob_{3}(j) ,
	\quad
	sum_3 = \sum_{j=1}^{10} components(\vec{d_3}) ,
\end{equation}
\begin{equation}	
	w_4 = \prod_{j=1}^{10} choice\_prob_{4}(j) ,
	\quad
	sum_4 = \sum_{j=1}^{10} components(\vec{d_4}) ,
\end{equation}
\begin{equation}	
	w_5 = \prod_{j=1}^{10} choice\_prob_{5}(j) ,
	\quad
	sum_5 = \sum_{j=1}^{10} components(\vec{d_5}) ,
\end{equation}
\begin{equation}
	EV(heads) = (\sum_{i=1}^{k}{w_i * sum_i}),
\end{equation}
\begin{equation}
	\enspace
	EV(heads) = (w_1 * sum_1 \enspace + \enspace w_2 * sum_2 \enspace + \enspace w_3 * sum_3 \enspace + \enspace w_4 * sum_4 \enspace + \enspace w_5 * sum_5)
\end{equation}
\begin{equation}
	\enspace
	Objective = maximize(w_1 * sum_1 \enspace + \enspace w_2 * sum_2 \enspace + \enspace w_3 * sum_3 \enspace + \enspace w_4 * sum_4 \enspace + \enspace w_5 * sum_5)
\end{equation}
\end{document} 