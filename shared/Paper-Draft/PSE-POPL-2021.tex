%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
%%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
\documentclass[acmsmall,review]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{POPL} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2022}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
%% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption
\usepackage{mathtools}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{forest}
\usepackage{csquotes}
\usepackage{minted}
\usepackage{multicol}
\usepackage{xcolor, soul}


%%% Colors %%%
\definecolor{darkgreen}{RGB}{0,128,0}

%%% Macros %%%

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\newcommand{\DeclareAutoPairedDelimiter}[3]{%
	\expandafter\DeclarePairedDelimiter\csname Auto\string#1\endcsname{#2}{#3}%
	\begingroup\edef\x{\endgroup
		\noexpand\DeclareRobustCommand{\noexpand#1}{%
			\expandafter\noexpand\csname Auto\string#1\endcsname*}}%
	\x}
\DeclareAutoPairedDelimiter{\deno}{\llbracket}{\rrbracket}

\newcommand*\Let[2]{\State #1 $\gets$ #2}
\newcommand*\cLet[3]{\State\ColorLine{#3} #1 $\gets$ #2}
\newcommand*\dom[1]{\mathrm{dom}\left( #1 \right)}
% For the Case statements
% Switch Statement Commands
% New definitions
\algnewcommand\algorithmicswitch{\textbf{switch}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%
% New "environments"
\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}%
\algtext*{EndSwitch}%
\algtext*{EndCase}%

% Highlight lines in algorithm environment
\makeatletter
% code borrowed from Andrew Stacey; See
% https://tex.stackexchange.com/a/50054/3954
\tikzset{%
	remember picture with id/.style={%
		remember picture,
		overlay,
		save picture id=#1,
	},
	save picture id/.code={%
		\edef\pgf@temp{#1}%
		\immediate\write\pgfutil@auxout{%
			\noexpand\savepointas{\pgf@temp}{\pgfpictureid}}%
	},
	if picture id/.code args={#1#2#3}{%
		\@ifundefined{save@pt@#1}{%
			\pgfkeysalso{#3}%
		}{
			\pgfkeysalso{#2}%
		}
	}
}

\def\savepointas#1#2{%
	\expandafter\gdef\csname save@pt@#1\endcsname{#2}%
}

\def\tmk@labeldef#1,#2\@nil{%
	\def\tmk@label{#1}%
	\def\tmk@def{#2}%
}

\tikzdeclarecoordinatesystem{pic}{%
	\pgfutil@in@,{#1}%
	\ifpgfutil@in@%
	\tmk@labeldef#1\@nil
	\else
	\tmk@labeldef#1,(0pt,0pt)\@nil
	\fi
	\@ifundefined{save@pt@\tmk@label}{%
		\tikz@scan@one@point\pgfutil@firstofone\tmk@def
	}{%
		\pgfsys@getposition{\csname save@pt@\tmk@label\endcsname}\save@orig@pic%
		\pgfsys@getposition{\pgfpictureid}\save@this@pic%
		\pgf@process{\pgfpointorigin\save@this@pic}%
		\pgf@xa=\pgf@x
		\pgf@ya=\pgf@y
		\pgf@process{\pgfpointorigin\save@orig@pic}%
		\advance\pgf@x by -\pgf@xa
		\advance\pgf@y by -\pgf@ya
	}%
}

\makeatother
% end of Andrew's code

% main command to draw the colored background
\newcounter{mymark}
\newcommand\ColorLine[1]{%
	\stepcounter{mymark}%
	\tikz[remember picture with id=mark-\themymark,overlay] {;}%
	\begin{tikzpicture}[remember picture,overlay]%
		\filldraw[#1]%
		let \p1=(pic cs:mark-\themymark), 
		\p2=(current page.east)  in 
		([xshift=-0.3em,yshift=-0.7ex]0,\y1)  rectangle ++([xshift=-1.2cm]\x2,\baselineskip);
	\end{tikzpicture}%
}%

% colored loops and declarations
\makeatletter
\algnewcommand\cRequire[1]{\item[\ColorLine{#1}\algorithmicrequire]}%
\algnewcommand\cEnsure[1]{\item[\ColorLine{#1}\algorithmicensure]}%
\algnewcommand\cState[1]{\State\ColorLine{#1}}%
\algnewcommand\cStatex[1]{\Statex\ColorLine{#1}}%
\algnewcommand\cComment[1]{\Comment\ColorLine{#1}}%

\algdef{SE}[WHILE]{cWhile}{ENDWHILE}%
[2]{\ColorLine{#2}\algorithmicwhile\ #1\ \algorithmicdo}%
{\algorithmicend\ \algorithmicwhile}%
\algdef{SE}[FOR]{cFor}{ENDFOR}%
[2]{\ColorLine{#2}\algorithmicfor\ #1\ \algorithmicdo}%
{\algorithmicend\ \algorithmicfor}%
\algdef{S}[FOR]{cForAll}%
[2]{\ColorLine{#2}\algorithmicforall\ #1\ \algorithmicdo}%
\algdef{SE}[LOOP]{cLoop}{ENDLOOP}%
[1]{\ColorLine{#1}\algorithmicloop}%
{\algorithmicend\ \algorithmicloop}%
\algdef{SE}[REPEAT]{cRepeat}{UNTIL}%
[1]{\ColorLine{#1}\algorithmicrepeat}%
[1]{\algorithmicuntil\ #1}%
\algdef{SE}[IF]{cIf}{ENDIF}%
[2]{\ColorLine{#2}\algorithmicif\ #1\ \algorithmicthen}%
{\algorithmicend\ \algorithmicif}%
\algdef{C}[IF]{IF}{cElsif}%
[2]{\ColorLine{#2}\algorithmicelse\ \algorithmicif\ #1\ \algorithmicthen}%
\algdef{Ce}[ELSE]{IF}{cElse}{ENDIF}%
[1]{\ColorLine{#1}\algorithmicelse}%
\algdef{SE}[SWITCH]{cSwitch}{EndSwitch}%
[2]{\ColorLine{#2}\algorithmicswitch\ #1\ \algorithmicdo}%
{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{cCase}{EndCase}%
[2]{\ColorLine{#2}\algorithmiccase\ #1}%
{\algorithmicend\ \algorithmiccase}%
\makeatother

\begin{document}
	
	%% Title information
	\title[PSE]{Probabilistic Symbolic Execution}         %% [Short Title] is optional;
	%% when present, will be used in
	%% header instead of Full Title.
	%\titlenote{with title note}             %% \titlenote is optional;
	%% can be repeated if necessary;
	%% contents suppressed with 'anonymous'
	%\subtitle{Subtitle}                     %% \subtitle is optional
	%\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
	%% can be repeated if necessary;
	%% contents suppressed with 'anonymous'
	
	
	%% Author information
	%% Contents and number of authors suppressed with 'anonymous'.
	%% Each author should be introduced by \author, followed by
	%% \authornote (optional), \orcid (optional), \affiliation, and
	%% \email.
	%% An author may have multiple affiliations and/or emails; repeat the
	%% appropriate command.
	%% Many elements are not rendered, but should be provided for metadata
	%% extraction tools.
	
	%% Author with single affiliation.
	\author{First1 Last1}
	\authornote{with author1 note}          %% \authornote is optional;
	%% can be repeated if necessary
	\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
	\affiliation{
		\position{Position1}
		\department{Department1}              %% \department is recommended
		\institution{Institution1}            %% \institution is required
		\streetaddress{Street1 Address1}
		\city{City1}
		\state{State1}
		\postcode{Post-Code1}
		\country{Country1}                    %% \country is recommended
	}
	\email{first1.last1@inst1.edu}          %% \email is recommended
	
	%% Author with two affiliations and emails.
	\author{First2 Last2}
	\authornote{with author2 note}          %% \authornote is optional;
	%% can be repeated if necessary
	\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
	\affiliation{
		\position{Position2a}
		\department{Department2a}             %% \department is recommended
		\institution{Institution2a}           %% \institution is required
		\streetaddress{Street2a Address2a}
		\city{City2a}
		\state{State2a}
		\postcode{Post-Code2a}
		\country{Country2a}                   %% \country is recommended
	}
	\email{first2.last2@inst2a.com}         %% \email is recommended
	\affiliation{
		\position{Position2b}
		\department{Department2b}             %% \department is recommended
		\institution{Institution2b}           %% \institution is required
		\streetaddress{Street3b Address2b}
		\city{City2b}
		\state{State2b}
		\postcode{Post-Code2b}
		\country{Country2b}                   %% \country is recommended
	}
	\email{first2.last2@inst2b.org}         %% \email is recommended
	
	
	%% Abstract
	%% Note: \begin{abstract}...\end{abstract} environment must come
	%% before \maketitle command
	\begin{abstract}
		TODO: Write Abstract
	\end{abstract}
	
	
	%% 2012 ACM Computing Classification System (CSS) concepts
	%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
	%% TODO: Get CSS Concepts
	\begin{CCSXML}
		<ccs2012>
		<concept>
		<concept_id>10011007.10011006.10011008</concept_id>
		<concept_desc>Software and its engineering~General programming languages</concept_desc>
		<concept_significance>500</concept_significance>
		</concept>
		<concept>
		<concept_id>10003456.10003457.10003521.10003525</concept_id>
		<concept_desc>Social and professional topics~History of programming languages</concept_desc>
		<concept_significance>300</concept_significance>
		</concept>
		</ccs2012>
	\end{CCSXML}
	
	\ccsdesc[500]{Software and its engineering~General programming languages}
	\ccsdesc[300]{Social and professional topics~History of programming languages}
	%% End of generated code
	
	
	%% Keywords
	%% comma separated list
	\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission
	
	
	%% \maketitle
	%% Note: \maketitle command must come after title commands, author
	%% commands, abstract environment, Computing Classification System
	%% environment and commands, and keywords command.
	\maketitle
	
	
	\section{Introduction}
	\label{sec:intro}
	
	One of the goals of symbolic execution is to identify whether a ``bad'' state (e.g. an \texttt{assert} failure) is reached, signifying a bug in the program.
	%
	In probabilistic programs, we are often more interested in either whether a ``bad'' state is reached too often, or, conversely, whether the ``good'' states are reached often enough.
	
	
	\subsection{Contributions}
	\label{sec:contrib}
	
	\section{Motivating Example}
	\label{sec:motiv_example}
	
	The Monty Hall problem~\cite{selvin1975} is a classic probability puzzle based on the American television show, \textit{Let's Make a Deal}, which showcases how subtle probabilistic reasoning can be.
	%
	The problem itself is simple:
	\begin{displayquote}
		You are a contestant on a gameshow and behind one of three doors there is a car and behind the others, goats.
		% 
		You pick a door and the host, who knows what is behind each of the doors, opens a different door, which has a goat.
		% 
		The host then offers you the choice to switch to the remaining door.
		% 
		Should you?
	\end{displayquote}
	While it may seem unintuitive, regardless of the contestant's original door choice, the contestant who always switches doors will win the car $\frac{2}{3}$ of the time, as opposed to a $\frac{1}{3}$ chance if the contestant sticks with their original choice.
	
	
	\begin{figure}\centering
		\inputminted[fontsize=\footnotesize,linenos]{c}{montyhall.c}
		\caption{C code for the Monty Hall Problem}
		\label{fig:montyhall}
	\end{figure}
	
	
	We can represent this problem as a probabilistic program, as shown in Fig.~\ref{fig:montyhall}, where $\mathtt{choice} \in [1,3]$ is the door which is originally chosen by the contestant and $\mathtt{door\_switch}$ is \texttt{true} if the contestant wants to switch doors when asked, and \texttt{false} otherwise.
	%
	If $\mathtt{door\_switch} = \mathtt{true}$, regardless of the value of \texttt{choice}, \texttt{monty\_hall} should return \texttt{true} (i.e. the car is won) $\frac{2}{3}$ of the time.
	%
	In general, the problem we aim to solve is: given a probabilistic program with discrete sampling statements, and a program property, how do we verify that the program satisfies the property?
	
	
	% One typical solution would be to run a simulation on random inputs and compute the probability of winning if $\mathtt{door\_switch} = \mathtt{true}$, and the probability of winning if $\mathtt{door\_switch} = \mathtt{false}$.
	% %
	% While for this program this would work as the input space is tiny, the resulting output distributions would be absent any formal guarantees and only be an approximation.
	% %
	% We instead develop a novel symbolic execution technique to provide a sound guarantee on the probability of certain events occurring.
	
	
	In symbolic execution, program inputs are replaced by \textit{symbolic} variables which can take on any value.
	%
	The program is then ``run'' on these symbolic variables and when a branch is reached execution proceeds along each of these two branches and the constraint is recorded in that path's, \textit{path condition}, which is represented by $\varphi$.
	%
	This yields an execution tree which shows us possible paths through the program.
	
	
	\begin{figure}
		\label{fig:montyhall_tree}
		\centering
		{\footnotesize
			\begin{forest}baseline,for tree=draw,
				[{$\mathtt{1}: c_0=\top$},align=center, base=bottom
				[{$\mathtt{4}: c_1 = \alpha = 1$},align=center, base=bottom
				[{$\mathtt{5}: c_2 = \beta$},align=center, base=bottom, node options={dotted,thick}, draw=red] %loss
				[{$\mathtt{5}: c_2 = \neg\beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen]] %win
				[{$\mathtt{4}: c_1 = \alpha \neq 1$},align=center, base=bottom
				[{$\mathtt{10}: c_2 = \alpha \neq 2$},align=center, base=bottom
				[{$\mathtt{12}: c_3 = \beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen ] % win
				[{$\mathtt{12}: c_3 = \neg\beta$},align=center, base=bottom, node options={dotted,thick}, draw=red]] % loss
				[{$\mathtt{10}: c_2 = \alpha = 2$},align=center, base=bottom
				[{$\mathtt{12}: c_3 = \beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen ] % win
				[{$\mathtt{12}: c_3 = \neg\beta$},align=center, base=bottom, node options={dotted,thick}, draw=red ]]]] % loss
			\end{forest}
		}
		\caption{Execution Tree for the Monty Hall Problem if the car is behind door 1.}
	\end{figure}
	
	
	Suppose we were to run traditional symbolic execution on the program in Fig~\ref{fig:montyhall} where the car was randomly chosen to be behind door 1.
	%
	The two inputs, \texttt{choice} and \texttt{door\_switch}, would become the symbolic variables $\alpha$ and $\beta$, respectively.
	%
	The execution tree is shown in Fig.~\ref{fig:montyhall_tree}.
	%
	For each node in the tree the line number of the branch statement and the path condition is given.
	%
	Leaves which are surrounded by a dashed (\tikz{\draw[dashed,line width=1pt] (0,0) -- (0.35,0) }), {\color{darkgreen} green} line represent the contestant winning the car (the function returning \texttt{true}), and those leaves which are surrounded by a dotted (\tikz{\draw[dotted,thick,line width=1pt] (0,0) -- (0.35,0) }), {\color{red} red} line represent the contestant losing the contest (the function returning \texttt{false}).
	%
	Symmetric trees can be made for the cases when the car is behind door 2 and door 3.
	
	
	While this tree can tell us that it is \textit{possible} to win (or lose) the car with any choice of initial door and decision to switch, it does not tell us how \textit{often} a contestant will for any initial door and decision to switch.
	%
	In theory, if we knew how likely it was to take one branch over another we could extend this reasoning to determine how often we would hit a winning leaf over a losing leaf.
	%
	\textbf{Our core idea is to represent probabilistic sampling statements also as symbolic variables.}
	%
	For the sake of presentation we refer to these as \textit{probabilistic} symbolic variables as opposed to, what we call, \textit{universal} symbolic variables which range over all possible values.
	%
	So, instead of asking for a random value, we replace the result of the sample with a probabilistic symbolic variable and record the distribution from which the sample is from.
	%
	We then are able to interpret a branch on a probabilistic symbolic variable as a conditioning operation on the originating distribution.
	
	
	Now let us return to the Monty Hall problem from Fig.~\ref{fig:montyhall}.
	%
	Let \texttt{car\_door} be represented by the probabilistic symbolic variable, $\delta$ and let \texttt{choice} and \texttt{door\_switch} be $\alpha$ and $\beta$, respectively, as before.
	%
	Instead of branching solely on $\alpha$ and $\beta$, we additionally branch on $\delta$.
	%
	The execution tree is presented in Fig.~\ref{fig:montyhall_tree_prob}.
	%
	Note that branches are omitted from the tree if which direction to traverse can be inferred by the current path condition.
	
	
	Since probabilistic symbolic variables originate from a distribution, we can determine the \textit{probability} of taking a certain branch by simply counting how many values from the distribution satisfy the guard condition.
	%
	For example, to figure out the probability of taking the \texttt{true} branch of the \texttt{if} condition on line 4 (denoted by \textbf{T} in Fig.~\ref{montyhall_tree_prob}), it suffices to count how many settings of $\delta$ satisfy $\alpha = \delta$ and divide by the total number of possible assignments to $\delta$ (i.e. 3).
	%
	However, since $\alpha$ is a symbolic variable we can only obtain a probability expression which is in terms of universal symbolic variables.
	%
	Let $[\cdot]$ denote Iverson brackets, where $[Q]=1$ if formula $Q$ is true, and 0 otherwise.
	%
	Then, $\text{\textbf{T}} = ([\alpha = 1] + [\alpha = 2] + [\alpha = 3])/3 = \frac{1}{3}$ as $\delta \in [1,2,3]$ and each setting is equally likely.
	%
	Similarly, $\text{\textbf{F}} = ([\alpha \neq 1] + [\alpha \neq 2] + [\alpha \neq 3])/3 = \frac{2}{3}$.
	
	
	\begin{figure}
		\label{fig:montyhall_tree_prob}
		\centering
		{\footnotesize
			\begin{forest}baseline,for tree=draw,
				[{$\mathtt{1}: c_0=\top$},align=center, base=bottom
				[{$\mathtt{4}: c_1 = \alpha = \delta$},align=center, base=bottom, edge label={node [midway,above] {\textbf{T}} }
				[{$\mathtt{5}: c_2 = \beta$},align=center, base=bottom, node options={dotted,thick}, draw=red ] %loss
				[{$\mathtt{5}: c_2 =  \neg\beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen ]] %win
				[{$\mathtt{4}: c_1 = \alpha \neq \delta$},align=center, base=bottom, edge label={node [midway,above] {\textbf{F}} }
				[{$\mathtt{7}: c_2 = \alpha \neq 1 \wedge \delta \neq 1$},align=center, base=bottom, 
				[{$\mathtt{12}: c_3 = \beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen ] %win
				[{$\mathtt{12}: c_3 = \neg\beta$},align=center, base=bottom, node options={dotted,thick}, draw=red ]] %loss
				[{$\mathtt{7}: c_2 = \alpha = 1 \vee \delta = 1$},align=center, base=bottom
				[{$\mathtt{10}: c_3 = \alpha \neq 2 \vee \delta \neq 2$},align=center, base=bottom
				[{$\mathtt{12}: c_4 = \beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen ] %win
				[{$\mathtt{12}: c_4 = \neg\beta$},align=center, base=bottom, node options={dotted,thick}, draw=red ]] %loss
				[{$\mathtt{10}: c_3 = \alpha = 2 \vee \delta = 2$},align=center, base=bottom
				[{$\mathtt{12}: c_4 = \beta$},align=center, base=bottom, node options={dashed}, draw=darkgreen ]%win
				[{$\mathtt{12}: c_4 = \neg\beta$},align=center, base=bottom, node options={dotted,thick}, draw=red ]]]]] %loss
			\end{forest}
		}
		\caption{Execution tree for the Monty Hall Problem with probabilistic symbolic variables.}
	\end{figure}
	
	
	With this \textit{probabilistic} execution tree in hand, let's return to the original question we wanted to answer: if the contestant switches doors, does their chances of winning the car exceed $\frac{1}{3}$?
	%
	Note that each path in the tree has a probability associated with it.
	%
	If we want to know the probability of winning if the contestant switches versus not, we can look at solely those paths in the tree which lead to a win.
	%
	To then figure out the probability of winning the car if the contestant switches we then can remove those paths where $\neg\beta$ is true, and then sum up the probabilities of the remaining paths. 
	%
	This results in an expression in terms of $\alpha$ and constants, which we can then evaluate where $\alpha = 1$, $\alpha = 2$, and $\alpha = 3$ and compare the probabilities.
	%
	In the end, we get that regardless the setting of $\alpha$ (i.e. the program variable, \texttt{choice}) the probability of winning the car if the contestant switches doors is exactly $\frac{2}{3}$.
	%
	We formalize this intuition in Section~\ref{sec:query_gen} by expressing this query in first order logic and use automated decision procedures to automate the solving.
	
	\section{Probabilistic Symbolic Execution Algorithm}
	\label{sec:pse}
	In this section, we present our technique for augmenting traditional symbolic execution to support probabilistic programs with discrete sampling instructions. 
	% 
	We begin with a short review of a traditional symbolic execution algorithm and then discuss how we calculate exact path probabilities.
	
	\subsection{Background}
	\label{sec:trad_sym_exec}
	
	% Symbolic Execution Algorithm.
	\begin{algorithm}
		\caption{Probabilistic Symbolic Execution Algorithm}
		\label{alg:symbex}
		\begin{algorithmic}[1]
			\Function{SymbEx}{$P_{prog} : Program$}
			\Let{$\varphi_{paths}$}{[]}, {$Ex_{stack}$} $\leftarrow$ {[]}, $\Delta \leftarrow$ {[]}, $\phi_{paths} \leftarrow \phi$, $P \leftarrow \phi$  \algorithmiccomment{Initialization}
			\Let{$I_{0}$}{\textsc{getStartInstruction}($P_{prog}$)}
			\Let{$S_{0}$}{[$I_{0}$, $\phi_{path}$, $\Delta$, $\phi$]} \algorithmiccomment{Empty Initial State}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{0}$})} \algorithmiccomment{Start with $S_{cur}$ in Execution Stack}
			\While{$Ex_{stack}$ != $\phi$}
			\Let{$S_{cur}$}{$Ex_{stack}$.\textsc{Pop}( )}, $I_{cur} \leftarrow S_{cur}[1]$ \algorithmiccomment{Start State, [$I_{0}$, $\phi_{path}$, $\Delta$]}
			\Switch{\textsc{instType}($I_{cur}$)} \label{line:inst_case}
			\Case{\texttt{make\_pse\_sym}} ($x_{var},  d_{dist}$) \algorithmiccomment{Create \texttt{fresh} Symbolic Variable} \label{line:make_pse}
			\Let{$I_{cur}$}{\textsc{getNextInstruction}($I_{cur}$)}
			\Let{$\phi_{path}, \Delta, P$}{{\textbf{PSESample}}({$x_{var},  d_{dist}$, $\phi_{path}$, $\Delta$, $P$})}
			\Let{$S_{cur}$}{[$I_{cur}$, $\phi_{path}$, $\Delta$, $P$]}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{cur}$})}
			\EndCase
			\Case{v := e} \algorithmiccomment{Assignment Instruction} \label{line:assign}
			\Let{$I_{cur}$}{\textsc{getNextInstruction}($I_{cur}$)}
			\Let{$\phi_{path}, \Delta, P$}{{\textbf{PSEAssignment}}({v, e, $\phi_{path}$, $\Delta$, $P$})}
			\Let{$S_{cur}$}{[$I_{cur}$, $\phi_{path}$, $\Delta$, $P$]}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{cur}$})}
			\EndCase
			\Case{\textbf{if} $(c_{sym})$ \textbf{then} $P_{1}$ \textbf{else} $P_{2}$} \algorithmiccomment{Branch Instruction}
			\Let{$Branch_{expr}$}{{\textbf{PSEBranch}}({$c_{sym}$, $\phi_{path}$, $\Delta$, $P$})} \label{line:branch}
			\State {$S_{true}$}, {$S_{false}$} $\leftarrow$ \textsc{ForkState} ($S_{cur}$, $I_{cur}$) \label{line:fork}
			\Let{$I_{1}$}{\textsc{getStartInstruction}($P_{1}$)} \Let{$I_{2}$} {\textsc{getStartInstruction}($P_{2}$)}	
			\Let{$S_{true}$}{[$I_{1}$, $\phi_{path} \wedge c_{sym}$, $\Delta$, $Branch_{expr}[0]$]} \label{line:true_state}
			\Let{$S_{false}$}{[$I_{2}$, $\phi_{path} \wedge (\neg c_{sym})$, $\Delta$, $Branch_{expr}[1]$]} \label{line:false_state}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{false}$})}
			\State {$Ex_{stack}$.\textsc{Push}({$S_{true}$})} \algorithmiccomment{Start with True State}
			\EndCase
			\Case{\textbf{HALT}} \algorithmiccomment{Terminate Instruction}
			\Let{$\varphi_{paths}$}{$\varphi_{paths}$.\textsc{Append}($\phi_{path}$)}		
			\EndCase
			\EndSwitch
			\EndWhile \\
			\Return{$\varphi_{paths}$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\textit{Symbolic execution} is a program analysis technique where a program is run on \textit{symbolic} inputs and all program operations are replaced with those which manipulate these symbolic variables.
	%
	We present a high-level description of how \textit{symbolic execution} works in Alg~\ref{alg:symbex}. 
	% 
	For each path in the program, a list of \textit{constraints} are stored that encodes the whole path as a \textit{logical}
	formula.
	% 
	These constraints are over \textit{program} variables that have been marked \textit{symbolic} by the user and are stored in the \textit{state} data structure as \textit{metadata} during the \textit{dynamic} symbolic execution of the program.
	% 
	Apart from \textit{path constraints}, the \textit{state} also contains a mapping of \textit{symbolic} variables to expressions that are either  \textit{symbolic} or \textit{concrete} (in the case of concrete execution of the program) and a list of \textit{instructions} currently getting executed as a part of the \textit{state}.	
	% 
	During symbolic execution, program state is encoded symbolically in two parts: a conjunctive formula, $\varphi$, consisting of the branch conditions which are true for that particular path, called a \textit{path condition}, and a mapping from program variables to symbolic expressions containing constants and \textit{symbolic variables}, $\sigma$.
	% 
	Each \textit{instruction} in the program is executed and depending upon the \textit{type} of the \textit{instruction} the \textit{state} along with the \textit{symbolic variables} mapping, ($\Delta$ in Alg~\ref{alg:symbex}) are updated as described in Algorithm~\ref{alg:symbex}.
	% 
	\textit{Symbolic variables} are assigned values by employing an \textsc{SMT Solver} for solving the current set of \textit{constraints} collected so far in the \textit{program path} and also by \textit{concretizing} some of the values that get evaluated as a result of \textit{concrete} execution (e.g. return value from external function calls).
	%
	When execution reaches an assignment of the form $\mathtt{x} = e$, where $e$ is a constant or program variable, $\sigma[\mathtt{x}]$ is either just the constant, $e$, or the symbolic representation of $e$, namely $\sigma[e]$.
	% 
	If $e$ is an expression, we recursively convert each program variable in $e$ to its corresponding symbolic expression found in $\sigma$ to construct a new symbolic execution, $e_{sym}$, and set $\sigma[\mathtt{x}] = e_{sym}$.
	% 
	When execution reaches a branch guarded by the condition $c$, execution proceeds down both branches, one where $\varphi = \varphi \wedge \sigma[c]$, and the other where $\varphi = \varphi \wedge \neg \sigma[c]$. 
	
	
	\subsection{Adding Probabilistic Sampling}
	We present the formalism of our approach on \textbf{pWhile}, a core imperative probabilistic programming language, as a model for more general languages:
	% 
	\[
	S := \mathbf{skip} \mid \mathtt{x} \leftarrow e \mid \mathtt{x} \xleftarrow{\$} d \mid S_1 ; S_2 \mid \mathbf{if}~e~\mathbf{then}~S_1~\mathbf{else}~S_2 \mid \mathbf{while}~e~\mathbf{do}~S 
	\]
	
	Above, $\mathtt{x}$ is a program variable, $e$ is an expression, and $d$ is a \textit{discrete} distribution expression which denotes which distribution the sample should be drawn from.
	% 
	We permit distribution expressions to be (optionally) parameterized by program variables.
	% 
	For example, $\mathsf{UniformInt}(1,\mathtt{x})$ is a uniform distribution which selects at random a value between 1 and $\mathtt{x}$ (inclusive), where $\mathtt{x} \geq 1$.
	% 
	In order to support sampling instructions we make the following additions to traditional symbolic execution:
	% 
	\begin{itemize}
		\item \textit{Probabilistic symbolic variables.} We distinguish two types of symbolic variables: \textit{universal} symbolic variables (identical to those in traditional symbolic execution), and \textit{probabilistic} symbolic variables.
		% 
		For each sampling instruction a new probabilistic symbolic variable is created to denote the result of sample.
		\item \textit{Distribution map.} We add a new mapping from probabilistic symbolic variables to distribution expressions, $P$, which tracks the distribution from which a probabilistic symbolic variable was originally sampled from.
		% 
		This is analogous to the symbolic variable map, $\sigma$, except for mapping probabilistic symbolic variables to distributions instead from program variables to symbolic expressions.
		\item \textit{Path probability.} For each path, we adjoin a path probability expression, $p$, which is parameterized by universal symbolic variables.
		% 
		Now each path can be identified by both its path condition and its probability.
	\end{itemize}
	
	\begin{algorithm}[H]
		\caption{PSE Assignment Algorithm}
		\label{alg:assign}
		\begin{algorithmic}[1]
			\Function{PSEAssignment}{$\mathtt{x}, e, \varphi, \sigma, P$}
			\Let{$e_{sym}$}{$\sigma[e]$}
			\State{$\sigma[\mathtt{x}] = e_{sym}$}
			\State\Return{$(\varphi,\sigma,P)$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{paragraph}{Assignment}
		For assignment statements of the form $\mathtt{x} \leftarrow e$, where $\mathtt{x}$ is a \textit{program} variable and $e$ is an expression, probabilistic symbolic execution proceeds identically to traditional symbolic execution, as detailed in Alg.~\ref{alg:assign}.
		%
		On the \textit{symbolic execution} side, the \textit{symbolic variable} mapping ($\Delta$) is updated with the result of the assignment operation is stored back in the current \textit{state} for further execution as shown in Line~\ref{line:assign} of Alg~\ref{alg:symbex}.
	\end{paragraph}
	
	\begin{algorithm}
		\caption{PSE Sampling Algorithm}
		\label{alg:sample}
		\begin{algorithmic}[1]
			\Function{PSESample}{$\mathtt{x}, d, \varphi, \sigma, P$}
			\Let{$\delta$}{Generate a fresh probabilistic symbolic variable}
			\State{$\sigma[\mathtt{x}] = \delta$}
			\State{$P[\delta] = d$}
			\State\Return{$(\varphi,\sigma,P)$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{paragraph}{Sampling}
		For sampling statements, $\mathtt{x} \xleftarrow{\$} d$, where $\mathtt{x}$ is a \textit{program} variable and $d$ is a distribution expression, Alg.~\ref{alg:sample} is used.
		% 
		A fresh probabilistic symbolic variable, $\delta$, is created, $\sigma$ is updated to be $\sigma[\mathtt{x}] = \delta$, and the original distribution $d$ is recorded in $P$ by setting $P[\delta] = d$.
		%
		On the \textit{symbolic execution} side, the updated \textit{Distribution Map} ($P$) with the result of sampling operation is stored back in the current \textit{state} for further execution as shown in Line~\ref{line:make_pse} of Alg~\ref{alg:symbex}.  
	\end{paragraph}
	
	\begin{algorithm}
		\caption{PSE Branch Algorithm}
		\label{alg:branch}
		\begin{algorithmic}[1]
			\Function{PSEBranch}{$c, \varphi, \sigma, P$}
			\Let{$c_{sym}$}{$\sigma[c]$}
			\Let{$(\delta_1,\ldots,\delta_n)$}{$\dom{P}$}
			\Let{$(d_1,\ldots,d_n)$}{$(P[\delta_1],\ldots,P[\delta_n])$}
			\Let{$p_c$}{$\frac{\displaystyle\sum_{(v_1,\ldots,v_n) \in \dom{d_1} \times \cdots\times \dom{d_n}} [(c_{sym} \wedge \varphi)\{\delta_1 \mapsto v_1,\ldots,\delta_n \mapsto v_n\}]}{\displaystyle\sum_{(v_1,\ldots,v_n) \in \dom{d_1} \times \cdots\times \dom{d_n}}[\varphi\{\delta_1 \mapsto v_1,\ldots,\delta_n \mapsto v_n\}]}$}
			\State\Return{$((\varphi \wedge c_{sym}, \sigma,P,p_c), (\varphi \wedge \neg c_{sym}, \sigma,P,1-p_c))$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\begin{paragraph}{Branches (Alg.~\ref{alg:branch})}
		Note that with the inclusion of probabilistic symbolic variables we can now either branch on universal or probabilistic symbolic variables (or both).
		% 
		Intuitively, branches are handled much the same in probabilistic symbolic execution as they are in traditional symbolic execution save for one detail: now branches have a probability associated with them.
		% 
		Given a guard expression $c$, how do we compute the probability of $c$ being true?
		
		
		To gain intuition, for now just consider the special case where the guard condition only references universal symbolic variables.
		% 
		Let $c_{sym}$ be the equivalent symbolic expression for the guard $c$ and assume that $c_{sym}$ does not reference any probabilistic symbolic variables.
		% 
		Note that which side of the branch is taken is solely determined by the setting of the univeral symbolic variables.
		% 
		Therefore, one side of the branch must have a probability of 1, and the other side, 0.
		% 
		We use Iverson brackets to formalize this idea; the probability of taking the ``true'' branch is $[c_{sym}]$, and the probability of taking the ``false'' branch is $[\neg c_{sym}]$.
		
		
		For probabilistic branches, i.e. guards which branch on probabilistic symbolic variables, computing the branch probability is trickier as given a fixed setting of the universal symbolic variables, it is unclear which branch execution will follow as this is dependent upon the sampling results.
		% 
		Without loss of generality, consider a branch of the form $\mathbf{if}~c~\mathbf{then}~S_1~\mathbf{else}~S_2$.
		% 
		As before, we define $c_{sym} = \sigma[c]$, or the symbolic expression representation of the guard expression, $c$, and we want to compute the probability of taking the ``true'' branch and the ``false'' branch, assuming execution has reached the start of the \texttt{if} condition.
		% 
		Since the path condition $\varphi$ records the necessary constraints on the universal and probabilistic symbolic variables which must hold in order to reach this \texttt{if} condition, we can view this probability a \textit{conditional probability}, or the probability that $c_{sym}$ holds given that $\varphi$ is satisfied.
		% 
		In formal notation, we aim to compute $\Pr[c_{sym} \mid \varphi] = \frac{\Pr[c_{sym}\wedge \varphi]}{\Pr[\varphi]}$.
		
		
		For now we restrict our view to uniform distributions, although we can support weighted distributions without further problems.
		% 
		Note that each probabilistic symbolic variable, $\delta$, is mapped to exactly one distribution, $d$, and therefore, $\delta \in \dom{d}$.
		% 
		So, assuming there are $n$ probabilistic symbolic variables, $\delta_1,\ldots,\delta_n$, and so $n$ distributions, $d_1,\ldots,d_n$, the set of all possible values $\delta_1,\ldots,\delta_n$ be is $\mathcal{D} = \dom{d_1} \times \cdots \times \dom{d_n}$.
		% 
		We then count the number of elements (or \textit{assignments}) from $\mathcal{D}$ which satisfy $c_{sym} \wedge \varphi$ and $\varphi$, and divide these two quantities as shown on line 5 of Alg.~\ref{alg:branch}.
		% 
		Note that $p_c$ is not necessarily a value, but rather a symbolic expression containing constants and universal symbolic variables.
		% 
		Additionally, we exploit the fact that the sum of the conditional probabilities of the branch outcomes is 1, which allows us to avoid computing the probability of taking the ``false'' branch directly. \\
		% 
		On the \textit{symbolic execution} side, upon reaching the \textit{branch} instruction at Line~\ref{line:branch} in Alg~\ref{alg:symbex}, the current \textit{state} ($S_{cur}$) is forked [Line~\ref{line:fork}] by making two identical copies of it. Furthermore, one additional constraint is appended to each of \textit{newly} created states ($S_{true}$ \& $S_{false}$) encoding the actual \textit{branch condition} ($c_{sym}$) [Line~\ref{line:true_state}] and it's negation ($\neg c_{sym}$) [Line~\ref{line:false_state}] representing the \textit{true} \& \textit{false} side of the \textit{branch}. 
		%
		These states are then added to the \textit{execution} stack containing \textit{states} that need to be explored next. The process continues untill all the \textit{states} in the \textit{execution} stack are explored.
	\end{paragraph}
	
	\begin{figure}[h]
		\centering
		\begin{subfigure}{.3\textwidth}
			\centering
			{\small
				\begin{algorithmic}[1]
					\State{$\mathtt{x}\xleftarrow{\$}\mathrm{UniformInt}(1,3)$}
					\State{$\mathtt{y}\xleftarrow{\$}\mathrm{UniformInt}(1,3)$}
					\If{$\mathtt{x} > 1$}
					\If{$\mathtt{x} < \mathtt{y}$}
					\State\Return{$\mathtt{True}$}
					\EndIf
					\Else
					\State\Return{$\mathtt{False}$}
					\EndIf
				\end{algorithmic}
			}
			\caption{Program}
			\label{fig:exam_program}
		\end{subfigure}
		\begin{subfigure}{.69\textwidth}
			\centering
			{\small
				\begin{forest}baseline,for tree=draw,
					[{$\varphi=\top$},align=center, base=bottom
					[{$\varphi = \delta_1 > 1$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{2}{3}$} }
					[{$\varphi = (\delta_1 > 1) \wedge (\delta_1 < \delta_2)$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{1}{6}$} }
					[{\texttt{True}}]]
					[{$\varphi = (\delta_1 > 1) \wedge \neg(\delta_1 < \delta_2)$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{5}{6}$} }
					[{\texttt{False}}]]]
					[{$\varphi = \neg(\delta_1 > 1)$}, align=center, base=bottom, edge label={node [midway,above] {$\frac{1}{3}$} }
					[{\texttt{False}}]]]
				\end{forest}
			}
			\caption{Execution Tree}
			\label{fig:exam_tree}
			
		\end{subfigure}
		\caption{An example program and its symbolic execution tree}
		\label{fig:example}
	\end{figure}
	
	\begin{paragraph}{Example}
		Consider the code in Fig.~\ref{fig:exam_program} and suppose we wish to calculate the probability of the program returning \texttt{True}.
		% 
		Following Alg.~\ref{alg:sample} for lines 1,2, we generate fresh probabilistic symbolic variables for $\mathtt{x}$ and $\mathtt{y}$, $\delta_1$ and $\delta_2$, respectively.
		% 
		We also store the distributions which $\delta_1$ and $\delta_2$ are samples from, namely the discrete uniform distribution $\mathcal{U}\{1,3\}$.
		% 
		In our notation, we say that $\sigma = \{ \mathtt{x} \mapsto \delta_1, \mathtt{y} \mapsto \delta_2 \}$ and $P = \{ \delta_1,\delta_2 \mapsto \mathcal{U}\{1,3\} \}$.
		% 
		Now following Alg.~\ref{alg:branch} to process line 4 of Fig.~\ref{fig:exam_program}, note that $\mathcal{D} = \{1,2,3\} \times \{1,2,3\}$ and 
		
		\begin{align*}
			p_c = \Pr[\delta_1 < \delta_2 \mid \delta_1 > 1] &= \frac{\Pr[(\delta_1 < \delta_2) \wedge (\delta_1 > 1)]}{\Pr[\delta_1 > 1]}\\
			&= \frac{\displaystyle\sum_{(v_1,v_2) \in \mathcal{D}} [(\delta_1 < \delta_2) \wedge (\delta_1 > 1)\{\delta_1 \mapsto v_1, \delta_2 \mapsto v_2\}]}{\displaystyle\sum_{(v_1,v_2) \in \mathcal{D}} [(\delta_1 > 1)\{\delta_1 \mapsto v_1\}]}\\
			&= \frac{1}{6}
		\end{align*}
		
		This probability means that the probability of taking the ``true'' branch of the inner \texttt{if} condition is only $\frac{1}{6}$, which makes sense as \texttt{x} is restricted to be either $2$ or $3$, but \texttt{y} can be either 1,2, or 3; however, only one combination of \texttt{x} and \texttt{y} will satisfy $\mathtt{x} < \mathtt{y}$, namely $\mathtt{x} = 2$ and $\mathtt{y} = 3$.
	\end{paragraph}
	
	We use a robust dynamic symbolic execution engine, \textsc{KLEE} to generate the \textit{path constraints} corresponding to each path that our tool explores. For the purpose of our implementation, we modify \textsc{KLEE} to support creation of \textit{probabilistic symbolic} variables whose values can be sampled from a distribution and process the \textit{path} constraints that are stored in the \textit{state} corresponding to the current execution of the program at each of \textbf{\textit{assignment}} [Algorithm~\ref{alg:symbex}, Line~\ref{line:assign}], \textbf{\textit{branch}} [Algorithm~\ref{alg:symbex}, Line~\ref{line:branch}] \& \textbf{\textit{sampling}} (\texttt{make\_pse\_symbolic()}) statements. [Algorithm~\ref{alg:symbex}, Line~\ref{line:make_pse}].
	
	\subsection{Query Generation}
	\label{sec:query_gen}
	
	At this point, we have an execution tree where each branch is annotated with the probability of taking the true and false branch.
	% 
	From this tree we construct a set of paths which are represented by a path condition and set of probabilities.
	% 
	If there are $n$ paths, and $\varphi_i$ is the $i^\text{th}$ path condition, and $p_{i_j}$ is the probability of the $j^{\text{th}}$ branch in the $i^{\text{th}}$ path, then we have $\{ (\varphi_1, \{p_{1_1},\ldots,p_{1_{k_1}}\}), \ldots, (\varphi_n, \{p_{n_1},\ldots,p_{n_{k_n}}\})\}$.
	% 
	To calculate the probability of an entire path, or equivalently, the probability of a path condition, $\varphi$, being true, we can simply multiply each of the branch probabilities.
	% 
	Recall that $p_{i_j}$ is the \textit{conditional} probability of the $j^{\text{th}}$ branch condition being true along path $i$.
	% 
	Since $\varphi_i$ is the conjunction of each of the $k_i$ branch conditions, the probability of taking the entire path can be computed using the rule $\Pr[A \wedge B] = \Pr[A \mid B]\Pr[B]$ where $A$ and $B$ are any two events.
	% 
	In other words, since $\varphi_i = c_{i_1} \wedge \cdots \wedge c_{i_{k_i}}$, then
	\begin{align*}
		\Pr[\varphi_i] &= \Pr[c_{i_1} \wedge \cdots \wedge c_{i_{k_i}}]\\
		&= \Pr[c_{i_1} \wedge (c_{i_2} \wedge \cdots \wedge c_{i_{{k_i}-1}} \wedge c_{i_{k_i}})]\\
		&= p_{i_1} \cdot \Pr[c_{i_2} \wedge \cdots \wedge c_{i_{k_i}}]\\
		&\vdots\\
		&= \displaystyle\prod_{j=1}^{k_i} p_{i_j}
	\end{align*}
	
	So, if we let $p_i = \prod_{j=1}^{k_i} p_{i_j}$, then we can simplify our set of paths to $\Phi = \{ (\varphi_1, p_1), \ldots, (\varphi_n, p_n)\}$.
	
	
	In our interpretation, the ultimate goal of probabilistic symbolic execution is to verify properties of probabilistic programs.
	% 
	In a probabilistic setting this often equates to either proving the upper bound of reaching some ``bad'' state, or proving the lower bound of reaching some ``good'' state.
	% 
	We achieve this through queries to an SMT solver, such as Z3~\cite{demoura2008}.
	% 
	There are three components to our queries: 1) a universal quantification over the universal symbolic variables, 2) a filtering condition specifying what a ``good'' or ``bad'' final state is, and 3) a desired upper/lower bound, potentially parameterized by universal symbolic variables.
	% 
	\begin{enumerate}
		\item If a program has $m$ universal symbolic variables, $\alpha_1,\ldots,\alpha_m$, we begin the query with a universal quantification, $\forall \alpha_1,\ldots,\alpha_m$, in order to reason over any setting of the non-probabilistic program variables.
		\item A \textit{filtering condition}, $\psi$, is a predicate which determines whether a path is considered ``bad'' or ``good'', depending on the property.
		% 
		Some example conditions are whether: a certain value is returned, a false positive (or negative) occurred, or a hash collision occurred.
		% 
		Out of all the paths, $\Phi$, we keep only those which satisfy $\psi$, $\Phi'$.
		% 
		We then sum over all of the paths in $\Phi'$, giving us the probability of $\psi$ occurring in program $S$:
		\[
		\sum_{(\varphi,p) \in \Phi'} [\varphi]\cdot p.
		\]
		Note that the probability expression $p$ is multiplied by $[\varphi]$, as during some settings of $\alpha_1,\ldots,\alpha_m$, the path represented by $\varphi$ might not be reachable, and so we should exclude that probability from the sum.
		% 
		The inclusion of the Iverson brackets achieves this desired behavior.
		\item Let $\delta$ (???) be the lower/upper bound \textit{expression} which we want to prove the $S$ does not violate.
	\end{enumerate}
	A general query then takes the form of
	\[
	\forall \alpha_1,\ldots,\alpha_m . \displaystyle \delta \bowtie \sum_{(\varphi,p) \in \Phi'} [\varphi]\cdot p 
	\]
	where $\sim$ is a binary relation (e.g. $>,<,\leq,\geq$).
	
	
	{\color{blue} \textbf{TODO: Finish up once the overview section is done}\\\\
		For example, in the Monty Hall problem as described in Section~\ref{sec:motiv_example}, we were only concerned with those paths that resulted in the contestant winning the car.
		% 
		So, we would filter on $\psi := win = true$, restricting the set of paths to be (TODO: Add on more after writing section 2).
		% 
		The probability of this occurring is then ... as ...
	}
	
	
	\subsection{Formalization}
	\label{sec:formalization}
	
	In this section we present the formalization of our method. First, we will present our notation and definitions, and then prove a soundness theorem for our technique.
	% 
	The goal of this section is to describe how $R=(\varphi,\sigma,P)$, the inputs to Alg.~\ref{alg:branch} is an abstraction of a \textit{distribution of program memories} before a branch guarded by a program expression $c$.
	
	\subsubsection{Notation \& Definitions}
	\label{sec:notation}
	
	To begin, we will define some notation:
	\begin{itemize}
		\item Let $Vars$ be the set of all program variables, $ForallSymVars$ be the set of all universal symbolic variables, $ProbSymVars$ be the set of all probabilistic symbolic variables, $SymVars = ForallSymVars \cup ProbSymVars$ be the combined set of all symbolic variables, and $Vals$ be the set of all values. 
		\item Let $a_f: ForallSymVars \rightarrow Vals$ be an assignment of universal symbolic variables to values and let $ForallAssign$ be the set of all such assignments.
		\item Similarly, let $a_p : ProbSymVars \rightarrow Vals$ be an assignment of probabilistic symbolic variables to values and let $ProbAssign$ be the set of all such assignments.
		\item Let $m : Vars \rightarrow Vals$ be a program memory which translates program variables into values, and let $Mems$ be the set of all program memories.
		\item Let $de : Mems \rightarrow (Vals \rightarrow [0,1])$ be a distribution expression parameterized by program memories, and let $DistExprs$ be the set of all distribution expressions.
		\item Let $d : ForallAssign \times Mems \rightarrow [0,1]$ be a distribution of program memories parameterized by assignments to universal symbolic variables and let $MemDists$ be the set of all parameterized distributions of program memories.
	\end{itemize}
	
	Additionally, we will use emphatic brackets for two purposes:
	\begin{itemize}
		\item If $e \in ProgExprs$ is a \textit{program} expression containing the program variables $\mathtt{x}_1,\ldots,\mathtt{x}_n \in Vars$, and $m \in Mems$, then
		\[
		\deno{e}m = \text{eval}(e[\mathtt{x}_1 \mapsto m(\mathtt{x}_1),\ldots,\mathtt{x}_n \mapsto m(\mathtt{x}_n)])
		\]
		\item If $e \in SymExprs$ is a \textit{symbolic} expression containing the symbolic variables $\alpha_1,\ldots,\alpha_n \in ForallSymVars$ and $\delta_1,\ldots,\delta_m \in ProbSymVars$, and $a_f \in ForallAssign$ and $a_p \in ProbAssign$, then
		\[
		\deno{e}a_fa_p = \text{eval}(e[\alpha_1\mapsto a_f(\alpha_1),\ldots,\alpha_n \mapsto a_f(\alpha_n), \delta_1 \mapsto a_p(\delta_1), \ldots, \delta_m \mapsto a_p(\delta_m)])
		\]
	\end{itemize}
	
	With this notation in hand, we can now define what it means for $R$ to be an abstraction of a distribution of programs memories.
	
	\begin{definition}
		\label{def:combined}
		Let $R = (\varphi, \sigma, P)$ be the abstraction generated by the symbolic execution algorithm where $\varphi: ForallAssign \times ProbAssign \rightarrow \{0,1\}$ denotes whether the path condition is true or false under the given assignments, $\sigma : Vars \rightarrow SymExprs$ is the mapping from program variables to symbolic expressions generated through symbolic execution, and $P : ForallAssign \rightarrow ProbSymVars \rightharpoonup (Vals \rightarrow [0,1])$  is the mapping from probabilistic symbolic variables to the distribution it is sampled from parameterized by assignments of forall symbolic variables.
		% 
		Additionally, for every assignment of forall symbolic variables, $a_f \in ForallAssign$, $\mathrm{domain}(P(a_f)) = \{\delta_1,\ldots,\delta_k\}$.
		% 
		Let $\alpha_1,\ldots,\alpha_l \in ForallSymVars$ be the forall symbolic variables which correspond to the $l$ parameters to the program.
		% 
		For every assignment of probabilistic and forall symbolic variables, $a_f \in ForallAssign, a_p \in ProbAssign$, let $\nu : ForallAssign \rightarrow (ProbAssign \rightarrow [0,1])$ be a distribution of assignments of probabilistic symbolic variables parameterized by assignments of forall symbolic variables, defined as
		\[
		\nu(a_f,a_p) \triangleq \prod_{i=1}^k \Pr_{v \sim P(a_f,\delta_i)}[v = a_p(\delta_i)].
		\]
		% 
		We say that a distribution $d$ satisfies our abstraction $R$ if, for all assignments of forall symbolic variables, $a_f \in ForallAssign$, $\displaystyle\Pr_{a_p' \sim \nu(a_f)}[\varphi(a_f,a_p') = 1] > 0$, and if $\mu : ForallAssign \rightarrow (ProbAssign \rightarrow [0,1])$ is defined as 
		\[
		\mu(a_f,a_p) = \cfrac{\Pr_{a_p' \sim \nu(a_f)}[a_p' = a_p \land \varphi(a_f,a_p') = 1]}{\Pr_{a_p' \sim \nu(a_f)}[\varphi(a_f,a_p')=1]}.
		\]
		Additionally, define $\text{convertToMem} : (Vars \rightarrow SymExprs) \rightarrow ForallAssign \rightarrow ProbAssign \rightarrow Mem$ as
		\begin{equation*}
			\text{convertToMem}(\sigma,a_f,a_p) \triangleq \lambda (\mathtt{x}: Vars)~.~\deno{\sigma(\mathtt{x})}a_fa_p,
		\end{equation*}
		and let $\text{convertFromMem}(\sigma,a_f,m) = (\text{convertToMem}(\sigma,a_f))^{-1}(m)$.
		% 
		Then,
		\[
		d(a_f,m) = \sum_{a_p \in \text{convertFromMem}(\sigma,a_f,m)} \mu(a_f,a_p).
		\]
	\end{definition}
	
	We additionally define the semantics for the three main types of statements which concerns probabilistic symbolic execution: assignments, probabilistic samples, and branches.
	
	\begin{definition}[Assignment Semantics]
		Let $d \in MemDists$ be a distribution of program memories parameterized by assignments to forall symbolic variables. Let $\mathtt{x} = e$ be an arbitrary assignment of the program variable $\mathtt{x} \in Vars$ to the program expression $e \in ProgExprs$. Let $\text{assign}_{\mathtt{x}=e} : Mems \rightarrow Mems$ is defined as
		\[
		\text{assign}_{\mathtt{x}=e}(m) = \lambda(\mathtt{y} : Vars)
		\begin{cases}
			\deno{e}m & \text{if $\mathtt{x} = \mathtt{y}$}\\
			m(\mathtt{y}) & \text{otherwise}
		\end{cases}
		\]
		and let $\text{unassign}_{\mathtt{x}=e} = \text{assign}_{\mathtt{x}=e}^{-1}$. Then we define $d_{\mathtt{x}=e}$ to be the distribution over program memories parameterized by assignments to forall symbolic variables after executing the assignment statement $\mathtt{x}=e$ to be
		\[
		d_{\mathtt{x}=e}(a_f,m) = \sum_{m' \in \text{unassign}_{\mathtt{x}=e}(m)} d(a_f,m').
		\]
	\end{definition}
	
	\begin{definition}[Sampling Semantics]
		Let $d \in MemDists$ be a distribution of program memories parameterized by assignments to forall symbolic variables. Let $\mathtt{x} \sim de$ be an arbitrary sampling instruction which assigns the program variable $\mathtt{x} \in Vars$ to a random element from the distribution of values parameterized by a memory, represented as a distribution expression $de \in DistExprs$. Let $\text{desample} : Vars \times Mems \rightarrow \mathcal{P}(Mems)$ be defined as
		\[
		\text{desample}(\mathtt{x},m) = \{ m'\in Mems \mid \forall (\mathtt{y} \in Vars)~.~(\mathtt{y} \neq \mathtt{x} \wedge m'(\mathtt{y}) = m(\mathtt{y}))\}.
		\]
		Then, we define $d_{\mathtt{x} \sim de}$ to be the distribution over program memories parameterized by assignments to forall symbolic variables after executing the sampling statement $\mathtt{x} \sim de$ to be
		\[
		d_{\mathtt{x} \sim de}(a_f,m) = \sum_{m' \in \text{desample}(m)} (\deno{de}a_f)(m(\mathtt{x})) \cdot d(a_f,m').
		\]
	\end{definition}
	
	\begin{definition}[Conditional Distribution of Program Memories]
		\label{def:cond}
		Let $a_f \in ForallAssign$ be an arbitrary assignment of forall symbolic variables, $c$ be a guard of an \texttt{if} condition, $d \in MemDists$ be a distribution of program memories parameterized by assignments to forall symbolic variables, and $\mathtt{x}_1,\ldots,\mathtt{x}_n \in Vars$ be all of the program variables in $c$. Then for all program memories $m \in Mems$, $d$ conditioned on a guard $c$ being true, represented as $d_c$ is defined as
		\[
		d_c(a_f,m) = \frac{\Pr_{m' \sim d(a_f)}\left[ m' = m \land \deno{c}m' = \mathtt{true} \right]}{\Pr_{m' \sim d(a_f)}\left[ \deno{c}m' = \mathtt{true} \right]}
		\]
		Similarly, for all program memories $m \in Mems$, $d$ conditioned on a guard $c$ being false, represented as $d_{\neg c}$ is defined as
		\[
		d_{\neg c}(a_f,m) = \frac{\Pr_{m' \sim d(a_f)}\left[ m' = m \land \deno{c}m' = \mathtt{false} \right]}{\Pr_{m' \sim d(a_f)}\left[ \deno{c}m' = \mathtt{false} \right]}
		\]
	\end{definition}
	
	\subsubsection{Proofs}
	\label{sec:proofs}
	
	\section{Implementation}
	\label{sec:implementation}
	
	{\color{red} KLEE Description Moved to \S\ref{sec:trad_sym_exec}} \\
	{\color{red} KLEE Modifications Moved to \S3.2} 
	
	\section{Case Studies}
	\label{sec:case_studies}
	In this section we will briefly explain each of the case studies that we use in our evaluation (Section~\ref{sec:eval}).
	% 
	For each case study, we will explain, (1) what the algorithm does, (2) which variables are concretized, universally quantified, and probabilistic, and (3) the property we aim to verify using our technique.
	% 
	Note that we frame the queries as an existential query and hope to get ``UNSAT'' in order to reason over all the possible values for the universal symbolic variables.
	
	\subsection{Freivalds' Algorithm}
	\label{sec:freivalds}
	
	Freivalds' algorithm~\cite{freivalds1977} is a randomized algorithm used to verify matrix multiplication in $\mathcal{O}(n^2)$ time.
	% 
	Given three $n \times n$ matrices $A,B$, and $C$, Freivalds' algorithm checks whether $A \times B = C$ by generating a random $n \times 1$ vector containing 0s and 1s, $\vec{r}$ and checks whether $A \times (B\vec{r}) - C\vec{r} = (0,\ldots,0)^T$.
	% 
	If so, the algorithm outputs ``Yes'', and ``No'' otherwise.
	% 
	However, if $A \times B \neq C$, the probability that the algorithm returns ``Yes'' is at most $\frac{1}{2}$.
	
	
	While the size of the matrices has to be concretized, the elements of the three matrices can be represented by universal symbolic variables and the elements of $r$ as probabilistic symbolic variables.
	% 
	We want to verify the false positive error rate of $\frac{1}{2}$.
	% 
	To do this, we can ask Z3, for a fixed $n$, whether there exist any $n \times n$ matrices $A,B$, and $C$ where $A \times B \neq C$ such that
	\[
	\Pr[\mathtt{freivalds}(A,B,C) = \text{Yes}] > \frac{1}{2}.
	\]
	
	\subsection{Randomized Response}
	\label{sec:randomized_response}
	
	Randomized response is a surveying technique which allows respondents to answer in a way that provides ``plausible deniability''
	% 
	Before answering the query, a coin is flipped.
	% 
	If ``tails'', then the respondent answers truthfully, if ``heads'', a second coin is flipped and the respondent answers ``Yes'' if ``heads'' and ``No'' if tails.
	% 
	In fact, this method is $(\ln 3, 0)$-differentially private.
	
	
	The answer the respondent would give if they answered truthfully can be represented with a universal symbolic variable, and the results of the two coin flips as probabilistic symbolic variables.
	% 
	With this model, we can prove $(\ln 3, 0)$ differential privacy by asking our method if there exists a setting of the ``truth'' such that
	\[
	\frac{\Pr[\text{Response} = \text{Yes} \mid \mathtt{text} = \text{Yes}]}{\Pr[\text{Response} = \text{Yes} \mid \mathtt{text} = \text{No}]} \neq 3
	\]
	and
	\[
	\frac{\Pr[\text{Response} = \text{No} \mid \mathtt{text} = \text{No}]}{\Pr[\text{Response} = \text{No} \mid \mathtt{text} = \text{Yes}]} \neq 3.
	\]
	
	\subsection{Reservoir Sampling}
	\label{sec:reservoir_sampling}
	
	\begin{algorithm}
		\caption{Reservoir Sampling}
		\label{alg:reservoir_sampling}
		\begin{algorithmic}[1]
			\Function{ReservoirSampling}{$A[1..n], S[1..k]$}
			\For{$i=1 \text{ to } k$}
			\Let{$S[i]$}{$A[i]$}
			\EndFor
			\For{$i=k+1\text{ to }n$}
			\Let{$j$}{$\mathrm{UniformInt}(1,i)$}
			\If{$j <= k$}
			\Let{$S[j]$}{$A[i]$}
			\EndIf
			\EndFor
			\State\Return{$S$}
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	Reservoir sampling is an online, randomized algorithm to get a simple random sample of $k$ elements from a population of $n$ elements.
	% 
	It uses uniform integer samples to maintain a set of $k$ elements drawn from the set of $n$ elements.
	% 
	For the full algorithm, see Alg.~\ref{alg:reservoir_sampling}.
	
	
	The sizes of both the population, $n$, and the sample, $k$, need to be concretized.
	% 
	The elements from $A$, are universal symbolic variables, and each sample, $j$, are probabilistic symbolic variables.
	% 
	The property that we want to check is whether each sample has an equal probability of being returned by Alg.~\ref{alg:reservoir_sampling}, namely $\frac{1}{\binom{n}{k}}$.
	
	\subsection{Schwartz-Zippel Lemma}
	\label{sec:schwartz-zippel}
	
	The Schwartz-Zippel lemma is a probabilistic method of polynomial identity testing, that is, the problem of determining whether a given multivariate polynomial is identially equal to 0 or not.
	% 
	Given a non-zero polynomial of total degree $d$, $P$, over a field $F$, and $r_1,\ldots,r_n$ selected at random from a subset of $F$, say $S$, then the lemma states that
	\[
	\Pr[P(r_1,\ldots,r_n) = 0] \leq \frac{d}{\abs{S}}.
	\]
	
	
	The number of terms in $P$, $n$, has to be concretized, the degrees of each of the terms, and the size of the subset $S$ all need to be concretized.
	% 
	The coefficients are represented as universal symbolic variables and $r_1,\ldots,r_n$ are probabilistic symbolic variables.
	% 
	The property that we want to check is whether there exists a non-zero polynomial, $P$, such that
	\[
	\Pr[P(r_1,\ldots,r_n) = 0] > \frac{d}{\abs{S}}.
	\]
	
	\subsection{Bloom Filter}
	\label{sec:bloom_filter}
	
	A Bloom filter is a space-efficient, probabilistic data structure used to rapidly determine whether an element is in a set.
	% 
	A Bloom filter is a bit-array of $n$ bits and $k$ associated hash functions, each of which maps elements in the set to places in the bit-array.
	% 
	To insert an element, $x$, into the filter, $x$ is hashed using each of the $k$ hash functions to get $k$ array positions.
	% 
	All of the bits at these positions are set to 1.
	% 
	To check whether an element $y$ is in the filter, $y$ is again hashed by each of the hash functions to get $k$ array positions.
	% 
	The bits at each of these positions are checked and the filter reports that $y$ is in the filter if, and only if, each of the bits are set to 1.
	% 
	Note that false positives are possible due to hash collisions, but false negatives are not.
	
	
	In order to bound the false positive error rate, most implementations of Bloom filters take in the expected number of elements to be inserted as well as the desired false positive error rate.
	% 
	From these two quantities, the optimal size of the bit-array, $n$, as well as the number of hash functions, $k$ can be computed.
	% 
	If $m$ is the expected number of elements and $\varepsilon$ is the desired error rate, then
	\begin{align*}
		n &= - \frac{m\ln \varepsilon}{(\ln 2)^2}\\
		k &= - \frac{\ln \varepsilon}{\ln 2}
	\end{align*}
	% 
	We want to prove that for a given $m$ and $\varepsilon$ that the actual false positive rate does not exceed $\varepsilon$.
	
	
	With our method, $m$ and $\varepsilon$ first need to be concretized. 
	% 
	Then, we insert $m$ elements $x_i$, where each $x_i$ can be represented using a universal symbolic variable.
	% 
	We model each of the $k$ uniform hash functions using the method described in Sec. (TODO: Insert bit about hash functions).
	% 
	We then want to check if there exist $x_1,\ldots,x_m$ such that the false positive rate exceeds $\varepsilon$.
	
	\subsection{Quicksort}
	\label{sec:quicksort}
	
	Quicksort is a popular sorting algorithm which uses partitioning in order to achieve efficient sorting.
	% 
	One way to choose a pivot element is by way of a uniform random sample.
	% 
	Using this pivot method, the expected number of pivots required is $1.386 n \log_2(n)$ where $n$ is the length of the array.
	% 
	If we concretize the length of the array, but represent the elements as universal symbolic variables, we can compute the expected number of pivots required to sort the array.
	
	
	\section{Evaluation}
	\label{sec:eval}
	
	\section{Related Work}
	\label{sec:related}
	{\color{red} Subhajit \& Sumit: If you could both start looking into related work (Mayhap, original PSE paper, Axprof, P4WN, PSI), that would be great!}
	
	{\color{blue}
		Write a paragraph or two about use of symbolic execution from other papers. In what ways has symbolic execution has been used and some traditional aspects.
		Write about AxProf, Original PSE paper [ISSTA 2012], Dice [Scaling Exact Inference for Discrete Probabilistic Programs, OOPSLA'20], Quantification of Software Changes through Probabilistic Symbolic Execution [ASE 2015], P4WN [ASPLOS'21], PSI [PLDI'20], Exact Inference for Higher-order Probabilistic Programs paper [FSE'15 QCoral] etc. Write the central idea in these papers and contrast with differences from approach presented in this paper. 
	}
	\section{Conclusion \& Future Work}
	\label{sec:conclusion}
	
	
	%% Acknowledgments
	\begin{acks}                            %% acks environment is optional
		%% contents suppressed with 'anonymous'
		%% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
		%% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
		%% acknowledge financial support and will be used by metadata
		%% extraction tools.
		% This material is based upon work supported by the
		% \grantsponsor{GS100000001}{National Science
		% Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
		% No.~\grantnum{GS100000001}{nnnnnnn} and Grant
		% No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
		% conclusions or recommendations expressed in this material are those
		% of the author and do not necessarily reflect the views of the
		% National Science Foundation.
	\end{acks}
	
	
	%% Bibliography
	\bibliography{main}
	
	
	%% Appendix
	\appendix
	\section{Appendix}
	
	Text of appendix \ldots
	
	\section{WIP Probabilistic Symbolic Execution} 
	\input{symbolic_execution.tex}
	
\end{document}
% Zach: Ignore for now, might swap out trees for this one later depending on feedback.
% \begin{figure}
%   \label{fig:montyhall_tree_prob}
%   \centering
%   {\tiny
%   \begin{forest}baseline,for tree=draw,
%     [{$\mathtt{1}: c_0=\top$},align=center, base=bottom
%       [{$\mathtt{4}: c_1 = \alpha = \delta$},align=center, base=bottom,edge label={node [midway,above] {$\frac{1}{3}$} }
%         [{$\mathtt{5}: c_2 = \beta$},align=center, base=bottom, draw=red ] %loss
%         [{$\mathtt{5}: c_2 =  \neg\beta$},align=center, base=bottom, draw=green ]] %win
%       [{$\mathtt{4}: c_1 = \alpha \neq \delta$},align=center, base=bottom,edge label={node [midway,above] {$\frac{2}{3}$} }
%         [{$\mathtt{7}: c_2 = \alpha \neq 1 \wedge \delta \neq 1$},align=center, base=bottom, 
%           [{$\mathtt{12}: c_3 = \beta$},align=center, base=bottom
%             [{$\mathtt{14}: c_4 = \alpha = 2$},align=center, base=bottom
%               [{$\mathtt{21}: c_5 = \delta = 3$},align=center, base=bottom, draw=green ] %win
%               [{$\mathtt{21}: c_5 = \delta \neq 3$},align=center, base=bottom, draw=red ]] % loss
%             [{$\mathtt{14}: c_4 = \alpha \neq 2$},align=center, base=bottom
%               [{$\mathtt{21}: c_5 = \delta = 2$},align=center, base=bottom, draw=green ] % win
%               [{$\mathtt{21}: c_5 = \delta \neq 2$},align=center, base=bottom, draw=red ]]] % loss
%           [{$\mathtt{12}: c_3 = \neg\beta$},align=center, base=bottom, draw=red ]] %loss
%         [{$\mathtt{7}: c_2 = \alpha = 1 \vee \delta = 1$},align=center, base=bottom
%           [{$\vdots$},align=center, base=bottom]]]]
%          % [{$\mathtt{12}: c_3 = \alpha \neq 2 \wedge \delta \neq 2$},align=center, base=bottom
%          %   [{$c_4 = \beta$},align=center, base=bottom
%          %     [{$c_5 = \alpha = 1$},align=center, base=bottom
%          %       [{$c_6 = \delta = 3$},align=center, base=bottom]
%          %       [{$c_6 = \delta \neq 3$},align=center, base=bottom]]
%          %     [{$c_5 = \alpha \neq 1$},align=center, base=bottom
%          %       [{$c_6 = \delta = 1$},align=center, base=bottom]
%          %       [{$c_6 = \delta \neq 1$},align=center, base=bottom]]]
%          %   [{$c_4 = \neg\beta$},align=center, base=bottom]]
%          % [{$\mathtt{12}: c_3 = \alpha = 2 \vee \delta = 2$},align=center, base=bottom
%          %   [{$c_4 = \beta$},align=center, base=bottom
%          %     [{$c_5 = \alpha = 1$},align=center, base=bottom
%          %       [{$c_6 = \delta = 2$},align=center, base=bottom]
%          %       [{$c_6 = \delta \neq 2$},align=center, base=bottom]]
%          %     [{$c_5 = \alpha \neq 1$},align=center, base=bottom
%          %       [{$c_6 = \delta = 1$},align=center, base=bottom]
%          %       [{$c_6 = \delta \neq 1$},align=center, base=bottom]]]
%          %   [{$c_4 = \neg\beta$},align=center, base=bottom]]]]]
%   \end{forest}
%   }
%   \caption{Partial execution tree for the Monty Hall Problem with probabilistic symbolic variables.}
% \end{figure}